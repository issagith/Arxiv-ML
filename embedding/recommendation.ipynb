{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "203c684d",
   "metadata": {},
   "source": [
    "# Recommendation System\n",
    "\n",
    "The goal here is to build a paper recommendation system using the embeddings spaces created by the classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb598bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from classifier.article_dataset import ArticleDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from classifier.models.mlp_classifier import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abdcb932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../classifier')  # Add parent directory to Python path\n",
    "from utils import custom_collate\n",
    "from models.mlp_classifier import MLPClassifier\n",
    "from models.bilstm_classifier import BiLSTMClassifier\n",
    "from models.bilstmattention_classifier import BiLSTMAttentionClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "902225e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['model_state_dict', 'hyperparameters', 'dataset_filters']),\n",
       " dict_keys(['vocab_size', 'embedding_dim', 'hidden_dim', 'num_classes', 'num_hidden_layers', 'dropout', 'freeze_embeddings']))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"mlp\"\n",
    "experiment_name = \"mlp_summary_fulldb\"\n",
    "checkpoint_path = os.path.join('..', 'classifier', 'experiments', folder, experiment_name, f'{experiment_name}.pth')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "hparams = checkpoint['hyperparameters']\n",
    "checkpoint.keys(), hparams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9fe0ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(\n",
       "  (embedding): Embedding(38894, 128)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (input_layer): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=128, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier(\n",
    "    vocab_size=hparams['vocab_size'],\n",
    "    embedding_dim=hparams['embedding_dim'],\n",
    "    hidden_dim=hparams['hidden_dim'],\n",
    "    num_classes=hparams['num_classes'],\n",
    "    num_hidden_layers=hparams['num_hidden_layers'],\n",
    "    dropout=hparams['dropout']\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee65d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"../classifier/data/articles.csv\"\n",
    "use_summary = True  \n",
    "classification_level = \"category\"  # ou \"sub_category\"\n",
    "selected_categories = None  # ou None pour toutes les catégories\n",
    "\n",
    "dataset = ArticleDataset(csv_file, use_summary=use_summary,\n",
    "                         classification_level=classification_level,\n",
    "                         selected_categories=selected_categories)\n",
    "\n",
    "filters = checkpoint.get('dataset_filters', {\"min_freq\": 5})\n",
    "dataset.apply_filters(filters)\n",
    "\n",
    "test_loader = DataLoader(dataset, batch_size=64, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b279c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = model.embedding.weight.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22cabcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=64, collate_fn=custom_collate, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6f101f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# concatenation remains on GPU\u001b[39;00m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(all_emb, dim=\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m emb = \u001b[43membed_all_in_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36membed_all_in_batches\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m all_emb = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpadded_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# move inputs to GPU\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadded_sequences\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_sequences\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# get embeddings on GPU\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\nsi\\M1\\Arxiv-ML\\classifier\\article_dataset.py:159\u001b[39m, in \u001b[36mArticleDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    156\u001b[39m     cat = row[\u001b[33m\"\u001b[39m\u001b[33msub_category\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    158\u001b[39m words = re.findall(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[a-z0-9]+\u001b[39m\u001b[33m'\u001b[39m, text.lower())\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m indices = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mword_to_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mword_to_index\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m<unk>\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwords\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m label = torch.tensor(\u001b[38;5;28mself\u001b[39m.class_to_index[cat], dtype=torch.long)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m indices, label\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def embed_all_in_batches():\n",
    "    model.eval()\n",
    "    all_emb = []\n",
    "    with torch.no_grad():\n",
    "        for padded_sequences, _ in dataloader:\n",
    "            # move inputs to GPU\n",
    "            padded_sequences = padded_sequences.to(device)\n",
    "            # get embeddings on GPU\n",
    "            emb = model.embedding(padded_sequences)  # [batch, seq_len, emb_dim]\n",
    "            # build mask on same device\n",
    "            mask = (padded_sequences != 0).unsqueeze(-1).float().to(device)\n",
    "            emb = emb * mask\n",
    "            # sum and average on GPU\n",
    "            sum_emb = emb.sum(dim=1)\n",
    "            lengths = mask.sum(dim=1)\n",
    "            avg_emb = sum_emb / lengths.clamp(min=1)\n",
    "            all_emb.append(avg_emb)\n",
    "    # concatenation remains on GPU\n",
    "    return torch.cat(all_emb, dim=0)\n",
    "\n",
    "emb = embed_all_in_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d70faaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1232614, 128])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c982850c",
   "metadata": {},
   "source": [
    "## Recommendation system\n",
    "\n",
    "now we have an embedding vector for each paper, we can use these to find similar papers.\n",
    "\n",
    "### First, we start with the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "129db7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# normalization L2\n",
    "emb_norm = emb.numpy().astype('float32')\n",
    "faiss.normalize_L2(emb_norm)\n",
    "\n",
    "# faiss index\n",
    "d = emb_norm.shape[1]\n",
    "index = faiss.IndexFlatIP(d)  \n",
    "index.add(emb_norm)\n",
    "\n",
    "def recommend_similar_papers(paper_idx: int, top_k: int = 5):\n",
    "    query = emb_norm[[paper_idx]]\n",
    "    D, I = index.search(query, top_k + 1)   \n",
    "    idxs, sims = [], []\n",
    "    for i, sim in zip(I[0], D[0]):\n",
    "        if i != paper_idx and len(idxs) < top_k:\n",
    "            idxs.append(int(i))\n",
    "            sims.append(float(sim))\n",
    "    return list(zip(idxs, sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35b3a1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for paper: \n",
      " Coexistence of distinct mobility edges in a 1D quasiperiodic mosaic\n",
      "  model\n",
      "\n",
      "title: Emergence of a superglass phase in the random hopping Bose-Hubbard model\n",
      "Similarity: 0.6029\n",
      "\n",
      "title: Solitonic in-gap modes in a superconductor-quantum antiferromagnet\n",
      "  interface\n",
      "Similarity: 0.5991\n",
      "\n",
      "title: Bose polarons in ultracold atoms in one dimension: beyond the Fröhlich\n",
      "  paradigm\n",
      "Similarity: 0.5945\n",
      "\n",
      "title: GPU Accelerated Discrete Element Method (DEM) Molecular Dynamics for\n",
      "  Conservative, Faceted Particle Simulations\n",
      "Similarity: 0.5916\n",
      "\n",
      "title: Stochastic pump of interacting particles\n",
      "Similarity: 0.5848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "paper_idx = 0\n",
    "recommendations = recommend_similar_papers(0, top_k=5)\n",
    "\n",
    "print(f\"Recommendations for paper: \\n {dataset.data.iloc[paper_idx]['title']}\")\n",
    "print()\n",
    "for idx, sim in recommendations:\n",
    "    summary = dataset.data.iloc[idx]['title']\n",
    "    print(f\"title: {summary}\")\n",
    "    print(f\"Similarity: {sim:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f51e2a",
   "metadata": {},
   "source": [
    "### Now we want to find the most similar paper to a given title not necessarily present in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955faaea",
   "metadata": {},
   "source": [
    "we embed the given using our classifier, then we find the most similar paper in the dataset using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00959d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'however' not found in vocabulary.\n",
      "Word 'ignorant' not found in vocabulary.\n",
      "Word 'impeding' not found in vocabulary.\n",
      "Word 'therefore' not found in vocabulary.\n",
      "Word 'repilot' not found in vocabulary.\n",
      "Word 'autoregressively' not found in vocabulary.\n",
      "Word 'repilot' not found in vocabulary.\n",
      "Word 'synergistically' not found in vocabulary.\n",
      "Word 'synthesizes' not found in vocabulary.\n",
      "Word 'prunes' not found in vocabulary.\n",
      "Word 'completes' not found in vocabulary.\n",
      "Word 'repilot' not found in vocabulary.\n",
      "Word 'moreover' not found in vocabulary.\n",
      "Word 'repilot' not found in vocabulary.\n",
      "Word 'repilot' not found in vocabulary.\n",
      "Recommendations for title: Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair\n",
      "\n",
      "Copiloting the Copilots: Fusing Large Language Models with Completion\n",
      "  Engines for Automated Program Repair\n",
      "Similarity: 0.8389\n",
      "\n",
      "TZ4Fabric: Executing Smart Contracts with ARM TrustZone\n",
      "Similarity: 0.6729\n",
      "\n",
      "Look Before You Leap: Enhancing Attention and Vigilance Regarding\n",
      "  Harmful Content with GuidelineLLM\n",
      "Similarity: 0.6706\n",
      "\n",
      "Token Highlighter: Inspecting and Mitigating Jailbreak Prompts for Large\n",
      "  Language Models\n",
      "Similarity: 0.6697\n",
      "\n",
      "Jailbreaking LLM-Controlled Robots\n",
      "Similarity: 0.6686\n",
      "\n",
      "Exploring the Role of Audio in Multimodal Misinformation Detection\n",
      "Similarity: 0.6666\n",
      "\n",
      "Let the Code LLM Edit Itself When You Edit the Code\n",
      "Similarity: 0.6663\n",
      "\n",
      "Simulate and Eliminate: Revoke Backdoors for Generative Large Language\n",
      "  Models\n",
      "Similarity: 0.6651\n",
      "\n",
      "IM-RAG: Multi-Round Retrieval-Augmented Generation Through Learning\n",
      "  Inner Monologues\n",
      "Similarity: 0.6573\n",
      "\n",
      "Unleashing Multicore Strength for Efficient Execution of Transactions\n",
      "Similarity: 0.6571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def embed(text):\n",
    "    words = re.findall(r'[a-z0-9]+', text.lower())\n",
    "    idxs = [dataset.word_to_index.get(word, 0) for word in words]\n",
    "    for w in words:\n",
    "        if w not in dataset.word_to_index:\n",
    "            print(f\"Word '{w}' not found in vocabulary.\")\n",
    "    w_embs = word_embeddings[idxs] # [seq_len, embedding_dim]\n",
    "    title = torch.mean(w_embs, dim=0)  # [embedding_dim]\n",
    "    return title.cpu().numpy().astype('float32')\n",
    "\n",
    "def recommend_by_title_embed(query_title: str, top_k: int = 5):\n",
    "    q_emb = embed(query_title)\n",
    "    # reshape to (1, dim) so FAISS can process it\n",
    "    q_emb = q_emb.reshape(1, -1)\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    D, I = index.search(q_emb, top_k)   # on récupère top_k voisins\n",
    "    return [(dataset.data.iloc[i]['title'], float(D[0, j]))\n",
    "            for j, i in enumerate(I[0])]\n",
    "\n",
    "ex_title = \"Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair\"\n",
    "ex_summary = \"\"\"During Automated Program Repair (APR), it can be challenging to synthesize correct patches for real-world systems in general-purpose programming languages. Recent Large Language Models (LLMs) have been shown to be helpful \"copilots\" in assisting developers with various coding tasks, and have also been directly applied for patch synthesis. However, most LLMs treat programs as sequences of tokens, meaning that they are ignorant of the underlying semantics constraints of the target programming language. This results in plenty of statically invalid generated patches, impeding the practicality of the technique. Therefore, we propose Repilot, a general code generation framework to further copilot the AI \"copilots\" (i.e., LLMs) by synthesizing more valid patches during the repair process. Our key insight is that many LLMs produce outputs autoregressively (i.e., token by token), resembling human writing programs, which can be significantly boosted and guided through a Completion Engine. Repilot synergistically synthesizes a candidate patch through the interaction between an LLM and a Completion Engine, which 1) prunes away infeasible tokens suggested by the LLM and 2) proactively completes the token based on the suggestions provided by the Completion Engine. Our evaluation on a subset of the widely-used Defects4j 1.2 and 2.0 datasets shows that Repilot outperforms state-of-the-art techniques by fixing 27% and 47% more bugs, respectively. Moreover, Repilot produces more valid and correct patches than the base LLM with the same budget. While we focus on leveraging Repilot for APR in this work, the overall approach is also generalizable to other code generation tasks.\"\"\"\n",
    "recommendations = recommend_by_title_embed(ex_summary, top_k=10)\n",
    "print(f\"Recommendations for title: {ex_title}\")\n",
    "print()\n",
    "for title, sim in recommendations:\n",
    "    print(f\"{title}\")\n",
    "    print(f\"Similarity: {sim:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb56516",
   "metadata": {},
   "source": [
    "## Observations \n",
    "\n",
    "It's useful if and only if one has a vague idea of a title and wants to find it. So it's basically a quick search engine.\n",
    "\n",
    "Otherwise, it doesn't recommend anything useful, it's just close semanticly. \n",
    "\n",
    "It can also be useful if you want to get a list of papers in a broad area of research ex : recommendation system, kernel methods, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
