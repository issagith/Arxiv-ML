{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8728976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f73e4acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to Python path\n",
    "from article_dataset import ArticleDataset\n",
    "from utils import custom_collate\n",
    "from models.mlp_classifier import MLPClassifier\n",
    "from models.bilstm_classifier import BiLSTMClassifier\n",
    "from models.bilstmattention_classifier import BiLSTMAttentionClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34b5d831",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.42 MiB for an array with shape (1, 1234798) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m ckpt_path = os.path.join(\u001b[33m\"\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mexperiments\u001b[39m\u001b[33m\"\u001b[39m, arch_key, exp_name, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pth\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m ds = \u001b[43mArticleDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCSV_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_summary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muse_summary\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclassification_level\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclassification_level\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mselected_categories\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mselected_categories\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m ds.apply_filters(FILTERS)\n\u001b[32m     32\u001b[39m dl = DataLoader(ds, batch_size=\u001b[32m32\u001b[39m, collate_fn=custom_collate)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\classifier\\notebooks\\..\\article_dataset.py:54\u001b[39m, in \u001b[36mArticleDataset.__init__\u001b[39m\u001b[34m(self, csv_file, use_summary, classification_level, filter_params, selected_categories)\u001b[39m\n\u001b[32m     51\u001b[39m         full = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmain\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33msub_category\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m full \u001b[38;5;129;01min\u001b[39;00m subs\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = (\u001b[38;5;28mself\u001b[39m.data.loc[\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m].reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Build vocabulary without frequency filtering\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mself\u001b[39m.vocab = \u001b[38;5;28mself\u001b[39m.create_vocab(apply_filter=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10360\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10362\u001b[39m op = frame_apply(\n\u001b[32m  10363\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10364\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10372\u001b[39m     kwargs=kwargs,\n\u001b[32m  10373\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10374\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\pandas\\core\\apply.py:1079\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1076\u001b[39m results = {}\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1079\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseries_gen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;49;00m\n\u001b[32m   1081\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mABCSeries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# If we have a view on v, we need to make a copy because\u001b[39;49;00m\n\u001b[32m   1084\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#  series_generator will swap out the underlying data\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\pandas\\core\\apply.py:1249\u001b[39m, in \u001b[36mFrameColumnApply.series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1247\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mseries_generator\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Generator[Series, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\n\u001b[32m   1250\u001b[39m     values = ensure_wrapped_if_datetimelike(values)\n\u001b[32m   1251\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) > \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mproperties.pyx:36\u001b[39m, in \u001b[36mpandas._libs.properties.CachedProperty.__get__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\pandas\\core\\apply.py:862\u001b[39m, in \u001b[36mFrameApply.values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    860\u001b[39m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\pandas\\core\\frame.py:12664\u001b[39m, in \u001b[36mDataFrame.values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m  12590\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m  12591\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> np.ndarray:\n\u001b[32m  12592\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m  12593\u001b[39m \u001b[33;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[32m  12594\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m  12662\u001b[39m \u001b[33;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[32m  12663\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m12664\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[39m, in \u001b[36mBlockManager.as_array\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m   1692\u001b[39m         arr.flags.writeable = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1693\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m     arr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[32m   1696\u001b[39m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1735\u001b[39m, in \u001b[36mBlockManager._interleave\u001b[39m\u001b[34m(self, dtype, na_value)\u001b[39m\n\u001b[32m   1733\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m   1734\u001b[39m     rl = blk.mgr_locs\n\u001b[32m-> \u001b[39m\u001b[32m1735\u001b[39m     arr = \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1736\u001b[39m     result[rl.indexer] = arr\n\u001b[32m   1737\u001b[39m     itemmask[rl.indexer] = \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheri\\nsi\\M1\\Arxiv-ML\\env\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:2588\u001b[39m, in \u001b[36mNumpyBlock.get_values\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   2586\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: DtypeObj | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> np.ndarray:\n\u001b[32m   2587\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype == _dtype_obj:\n\u001b[32m-> \u001b[39m\u001b[32m2588\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_dtype_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2589\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.values\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 9.42 MiB for an array with shape (1, 1234798) and data type object"
     ]
    }
   ],
   "source": [
    "CSV_FILE = \"../data/articles.csv\"\n",
    "FILTERS = {'min_freq': 5}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_classes = {\n",
    "    'mlp': MLPClassifier,\n",
    "    'bilstm': BiLSTMClassifier,\n",
    "    'bilstm_att': BiLSTMAttentionClassifier\n",
    "}\n",
    "\n",
    "experiments = {\n",
    "    'math_sub_cat':      {'selected_categories': ['math'], 'classification_level': 'sub_category', 'use_summary': True},\n",
    "    'math_sub_cat_title':{'selected_categories': ['math'], 'classification_level': 'sub_category', 'use_summary': False},\n",
    "    'summary_fulldb':    {'selected_categories': None,      'classification_level': 'category',     'use_summary': True},\n",
    "    'title_fulldb':      {'selected_categories': None,      'classification_level': 'category',     'use_summary': False}\n",
    "}\n",
    "\n",
    "# Chargement de chaque modèle et dataset\n",
    "loaded = {}\n",
    "for arch_key, ModelClass in model_classes.items():\n",
    "    for exp_suffix, cfg in experiments.items():\n",
    "        exp_name = f\"{arch_key}_{exp_suffix}\"\n",
    "        ckpt_path = os.path.join(\"..\", \"experiments\", arch_key, exp_name, f\"{exp_name}.pth\")\n",
    "        # Dataset\n",
    "        ds = ArticleDataset(\n",
    "            CSV_FILE,\n",
    "            use_summary=cfg['use_summary'],\n",
    "            classification_level=cfg['classification_level'],\n",
    "            selected_categories=cfg['selected_categories']\n",
    "        )\n",
    "        ds.apply_filters(FILTERS)\n",
    "        dl = DataLoader(ds, batch_size=32, collate_fn=custom_collate)\n",
    "        # Chargement du checkpoint\n",
    "        checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "        hparams = checkpoint['hyperparameters']\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "        # Détection automatique de l'architecture\n",
    "        model = None\n",
    "        for key, Cls in model_classes.items():\n",
    "            try:\n",
    "                tmp = Cls(\n",
    "                    hparams['vocab_size'],\n",
    "                    hparams['embedding_dim'],\n",
    "                    hparams['hidden_dim'],\n",
    "                    hparams['num_classes'],\n",
    "                    hparams['num_hidden_layers'],\n",
    "                    hparams['dropout']\n",
    "                ).to(device)\n",
    "                tmp.load_state_dict(state_dict)\n",
    "                tmp.eval()\n",
    "                model = tmp\n",
    "                arch_detected = key\n",
    "                break\n",
    "            except RuntimeError:\n",
    "                continue\n",
    "        if model is None:\n",
    "            raise RuntimeError(f\"Impossible de charger {exp_name}: aucun modèle compatible n'a accepté le state_dict\")\n",
    "        loaded[exp_name] = {'dataset': ds, 'dataloader': dl, 'model': model, 'arch': arch_detected}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ebaf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'bilstm_math_sub_cat'\n",
    "\n",
    "model = loaded[experiment_name]['model']\n",
    "dataloader = loaded[experiment_name]['dataloader']\n",
    "device = next(model.parameters()).device\n",
    "print(f\"Architecture détectée : {loaded[experiment_name]['arch']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8968999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, wtoi):\n",
    "    tokens = text.split()\n",
    "    indices = [wtoi.get(token, wtoi.get(\"<UNK>\", 0)) for token in tokens]\n",
    "    return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "def predict(text, model, wtoi, device):\n",
    "    input_tensor = preprocess_text(text, wtoi).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        return model(input_tensor)\n",
    "    \n",
    "test_title = \"maths\"\n",
    "test_text = \"The attention mechanism is a key component of transformer models, allowing them to focus on relevant parts of the input sequence.\"\n",
    "predictions = predict(test_title, model_mlp_cat_title, dataset_mlp_cat_title.word_to_index, device)\n",
    "predicted_class = torch.argmax(predictions, dim=1).item()\n",
    "print(f\"Predicted class for '{test_title}': {dataset_mlp_cat_title.index_to_class[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "076c91ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['model_state_dict', 'hyperparameters', 'dataset_filters']),\n",
       " dict_keys(['vocab_size', 'embedding_dim', 'hidden_dim', 'num_classes', 'num_hidden_layers', 'dropout', 'freeze_embeddings']))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"mlp\"\n",
    "experiment_name = \"mlp_title_fulldb\"\n",
    "checkpoint_path = os.path.join('..', 'experiments', folder, experiment_name, f'{experiment_name}.pth')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "hparams = checkpoint['hyperparameters']\n",
    "checkpoint.keys(), hparams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da1a5fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(\n",
       "  (embedding): Embedding(38894, 128)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (input_layer): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=128, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp_cat_title = MLPClassifier(\n",
    "    vocab_size=hparams['vocab_size'],\n",
    "    embedding_dim=hparams['embedding_dim'],\n",
    "    hidden_dim=hparams['hidden_dim'],\n",
    "    num_classes=hparams['num_classes'],\n",
    "    num_hidden_layers=hparams['num_hidden_layers'],\n",
    "    dropout=hparams['dropout']\n",
    ").to(device)\n",
    "\n",
    "model_mlp_cat_title.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_mlp_cat_title.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d754d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"../data/articles.csv\"\n",
    "use_summary = False  \n",
    "classification_level = \"category\"\n",
    "selected_categories = None\n",
    "\n",
    "dataset_mlp_cat_title = ArticleDataset(csv_file, use_summary=use_summary,\n",
    "                         classification_level=classification_level,\n",
    "                         selected_categories=selected_categories)\n",
    "# appliquer mêmes filtres\n",
    "filters = checkpoint.get('dataset_filters', {\"min_freq\": 5})\n",
    "dataset_mlp_cat_title.apply_filters(filters)\n",
    "\n",
    "# découpe train/test si nécessaire, mais ici on utilise tout pour inférence\n",
    "test_loader = DataLoader(dataset_mlp_cat_title, batch_size=64, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c61a8bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for 'maths': math\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text, wtoi):\n",
    "    tokens = text.split()\n",
    "    indices = [wtoi.get(token, wtoi.get(\"<UNK>\", 0)) for token in tokens]\n",
    "    return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "def predict(text, model, wtoi, device):\n",
    "    input_tensor = preprocess_text(text, wtoi).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        return model(input_tensor)\n",
    "    \n",
    "test_title = \"maths\"\n",
    "test_text = \"The attention mechanism is a key component of transformer models, allowing them to focus on relevant parts of the input sequence.\"\n",
    "predictions = predict(test_title, model_mlp_cat_title, dataset_mlp_cat_title.word_to_index, device)\n",
    "predicted_class = torch.argmax(predictions, dim=1).item()\n",
    "print(f\"Predicted class for '{test_title}': {dataset_mlp_cat_title.index_to_class[predicted_class]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
