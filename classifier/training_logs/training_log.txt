loading projection weights from data\word2vec-google-news-300.bin
KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from data\\word2vec-google-news-300.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2025-03-28T12:12:26.402791', 'gensim': '4.3.3', 'python': '3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'}
loss: 2.950927  [   64/984410]
loss: 2.241919  [ 6464/984410]
loss: 1.757927  [12864/984410]
loss: 1.330142  [19264/984410]
loss: 1.447918  [25664/984410]
loss: 0.999999  [32064/984410]
loss: 1.280000  [38464/984410]
loss: 1.150352  [44864/984410]
loss: 1.066390  [51264/984410]
loss: 0.911435  [57664/984410]
loss: 1.051792  [64064/984410]
loss: 1.024280  [70464/984410]
loss: 1.133228  [76864/984410]
loss: 1.185315  [83264/984410]
loss: 1.266802  [89664/984410]
loss: 1.270013  [96064/984410]
loss: 1.149909  [102464/984410]
loss: 0.983659  [108864/984410]
loss: 0.912345  [115264/984410]
loss: 0.907420  [121664/984410]
loss: 1.021102  [128064/984410]
loss: 1.108410  [134464/984410]
loss: 0.905045  [140864/984410]
loss: 1.170588  [147264/984410]
loss: 1.127630  [153664/984410]
loss: 0.944350  [160064/984410]
loss: 0.985148  [166464/984410]
loss: 1.009781  [172864/984410]
loss: 1.008923  [179264/984410]
loss: 0.513424  [185664/984410]
loss: 0.899513  [192064/984410]
loss: 0.620088  [198464/984410]
loss: 0.655937  [204864/984410]
loss: 0.948210  [211264/984410]
loss: 1.216491  [217664/984410]
loss: 0.883225  [224064/984410]
loss: 1.285388  [230464/984410]
loss: 0.840726  [236864/984410]
loss: 0.960859  [243264/984410]
loss: 1.018028  [249664/984410]
loss: 0.559985  [256064/984410]
loss: 0.870289  [262464/984410]
loss: 0.863867  [268864/984410]
loss: 1.122347  [275264/984410]
loss: 0.707754  [281664/984410]
loss: 0.848356  [288064/984410]
loss: 0.964260  [294464/984410]
loss: 0.634017  [300864/984410]
loss: 0.929775  [307264/984410]
loss: 0.691511  [313664/984410]
loss: 1.013041  [320064/984410]
loss: 0.956204  [326464/984410]
loss: 0.801414  [332864/984410]
loss: 0.919050  [339264/984410]
loss: 0.569213  [345664/984410]
loss: 0.872244  [352064/984410]
loss: 0.851686  [358464/984410]
loss: 1.175255  [364864/984410]
loss: 0.934461  [371264/984410]
loss: 1.188814  [377664/984410]
loss: 0.913235  [384064/984410]
loss: 0.637657  [390464/984410]
loss: 0.759967  [396864/984410]
loss: 0.639103  [403264/984410]
loss: 1.016845  [409664/984410]
loss: 0.776966  [416064/984410]
loss: 1.132929  [422464/984410]
loss: 0.705873  [428864/984410]
loss: 0.714043  [435264/984410]
loss: 0.965576  [441664/984410]
loss: 0.848026  [448064/984410]
loss: 1.190428  [454464/984410]
loss: 1.073401  [460864/984410]
loss: 0.889918  [467264/984410]
loss: 1.080239  [473664/984410]
loss: 0.886217  [480064/984410]
loss: 0.884106  [486464/984410]
loss: 0.830149  [492864/984410]
loss: 0.624701  [499264/984410]
loss: 0.816121  [505664/984410]
loss: 0.784705  [512064/984410]
loss: 0.807938  [518464/984410]
loss: 1.069715  [524864/984410]
loss: 0.990350  [531264/984410]
loss: 0.720625  [537664/984410]
loss: 0.609652  [544064/984410]
loss: 0.963433  [550464/984410]
loss: 0.872115  [556864/984410]
loss: 1.011672  [563264/984410]
loss: 0.834847  [569664/984410]
loss: 0.891799  [576064/984410]
loss: 0.643767  [582464/984410]
loss: 0.819410  [588864/984410]
loss: 0.670420  [595264/984410]
loss: 0.827963  [601664/984410]
loss: 0.706193  [608064/984410]
loss: 0.986764  [614464/984410]
loss: 0.940326  [620864/984410]
loss: 0.872584  [627264/984410]
loss: 1.191056  [633664/984410]
loss: 0.580926  [640064/984410]
loss: 0.818711  [646464/984410]
loss: 0.820597  [652864/984410]
loss: 0.549664  [659264/984410]
loss: 0.749186  [665664/984410]
loss: 0.597463  [672064/984410]
loss: 0.799379  [678464/984410]
loss: 0.745041  [684864/984410]
loss: 0.736067  [691264/984410]
loss: 0.884874  [697664/984410]
loss: 0.644237  [704064/984410]
loss: 0.970192  [710464/984410]
loss: 0.973829  [716864/984410]
loss: 0.736180  [723264/984410]
loss: 0.782199  [729664/984410]
loss: 0.700168  [736064/984410]
loss: 1.031756  [742464/984410]
loss: 0.935597  [748864/984410]
loss: 0.644936  [755264/984410]
loss: 0.776384  [761664/984410]
loss: 0.810869  [768064/984410]
loss: 0.889345  [774464/984410]
loss: 0.665651  [780864/984410]
loss: 0.835508  [787264/984410]
loss: 0.918719  [793664/984410]
loss: 0.779805  [800064/984410]
loss: 0.605898  [806464/984410]
loss: 0.646194  [812864/984410]
loss: 0.852955  [819264/984410]
loss: 0.711259  [825664/984410]
loss: 0.589545  [832064/984410]
loss: 0.661839  [838464/984410]
loss: 0.646546  [844864/984410]
loss: 0.732161  [851264/984410]
loss: 0.562286  [857664/984410]
loss: 1.029653  [864064/984410]
loss: 0.777696  [870464/984410]
loss: 0.741062  [876864/984410]
loss: 0.483625  [883264/984410]
loss: 0.497540  [889664/984410]
loss: 0.697562  [896064/984410]
loss: 0.882213  [902464/984410]
loss: 0.655476  [908864/984410]
loss: 0.556598  [915264/984410]
loss: 0.586441  [921664/984410]
loss: 0.546626  [928064/984410]
loss: 0.587930  [934464/984410]
loss: 0.875156  [940864/984410]
loss: 0.728961  [947264/984410]
loss: 0.707310  [953664/984410]
loss: 1.027768  [960064/984410]
loss: 0.717175  [966464/984410]
loss: 0.722500  [972864/984410]
loss: 0.859534  [979264/984410]
Epoch 1/3, Training Loss (epoch average): 0.8927, Test Loss: 0.9445, Test Accuracy: 69.32%
loss: 0.698574  [   64/984410]
loss: 0.546705  [ 6464/984410]
loss: 0.746464  [12864/984410]
loss: 0.751206  [19264/984410]
loss: 0.910407  [25664/984410]
loss: 0.698682  [32064/984410]
loss: 0.569212  [38464/984410]
