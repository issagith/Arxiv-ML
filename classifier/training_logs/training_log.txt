loading projection weights from data\word2vec-google-news-300.bin
KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from data\\word2vec-google-news-300.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2025-03-28T12:50:19.173412', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'}
loss: 2.922398  [   64/984410]
loss: 1.756819  [ 6464/984410]
loss: 1.557408  [12864/984410]
loss: 1.344061  [19264/984410]
loss: 1.034779  [25664/984410]
loss: 1.126005  [32064/984410]
loss: 0.998172  [38464/984410]
loss: 1.080509  [44864/984410]
loss: 0.918000  [51264/984410]
loss: 1.026793  [57664/984410]
loss: 1.111264  [64064/984410]
loss: 1.296428  [70464/984410]
loss: 0.804162  [76864/984410]
loss: 1.036426  [83264/984410]
loss: 1.125072  [89664/984410]
loss: 0.915524  [96064/984410]
loss: 1.145388  [102464/984410]
loss: 0.753901  [108864/984410]
loss: 0.901299  [115264/984410]
loss: 0.777913  [121664/984410]
loss: 1.125700  [128064/984410]
loss: 0.815516  [134464/984410]
loss: 0.574906  [140864/984410]
loss: 1.077325  [147264/984410]
loss: 0.984557  [153664/984410]
loss: 0.780099  [160064/984410]
loss: 0.791235  [166464/984410]
loss: 0.896781  [172864/984410]
loss: 0.809749  [179264/984410]
loss: 0.904515  [185664/984410]
loss: 0.828239  [192064/984410]
loss: 1.194015  [198464/984410]
loss: 1.097628  [204864/984410]
loss: 1.021486  [211264/984410]
loss: 0.788647  [217664/984410]
loss: 0.994332  [224064/984410]
loss: 1.059228  [230464/984410]
loss: 1.112372  [236864/984410]
loss: 0.960943  [243264/984410]
loss: 1.035290  [249664/984410]
loss: 0.740560  [256064/984410]
loss: 0.887148  [262464/984410]
loss: 0.945157  [268864/984410]
loss: 0.940769  [275264/984410]
loss: 1.080573  [281664/984410]
loss: 0.730223  [288064/984410]
loss: 0.887967  [294464/984410]
loss: 0.706054  [300864/984410]
loss: 1.064458  [307264/984410]
loss: 0.890556  [313664/984410]
loss: 0.624519  [320064/984410]
loss: 0.952232  [326464/984410]
loss: 0.570956  [332864/984410]
loss: 1.059725  [339264/984410]
loss: 0.897229  [345664/984410]
loss: 0.878019  [352064/984410]
loss: 0.688428  [358464/984410]
loss: 0.860131  [364864/984410]
loss: 0.851748  [371264/984410]
loss: 0.778259  [377664/984410]
loss: 0.885081  [384064/984410]
loss: 0.746775  [390464/984410]
loss: 0.771312  [396864/984410]
loss: 0.941100  [403264/984410]
loss: 0.971882  [409664/984410]
loss: 0.616080  [416064/984410]
loss: 0.690026  [422464/984410]
loss: 0.521089  [428864/984410]
loss: 0.746989  [435264/984410]
loss: 0.834646  [441664/984410]
loss: 0.579735  [448064/984410]
loss: 0.776751  [454464/984410]
loss: 0.645230  [460864/984410]
loss: 0.951815  [467264/984410]
loss: 0.575965  [473664/984410]
loss: 0.858488  [480064/984410]
loss: 1.095786  [486464/984410]
loss: 0.742751  [492864/984410]
loss: 0.830473  [499264/984410]
loss: 0.870708  [505664/984410]
loss: 0.518763  [512064/984410]
loss: 0.818428  [518464/984410]
loss: 0.804944  [524864/984410]
loss: 0.829671  [531264/984410]
loss: 0.478462  [537664/984410]
loss: 0.984218  [544064/984410]
loss: 0.756017  [550464/984410]
loss: 0.674685  [556864/984410]
loss: 0.824714  [563264/984410]
loss: 0.677853  [569664/984410]
loss: 0.899643  [576064/984410]
loss: 0.662356  [582464/984410]
loss: 0.836428  [588864/984410]
loss: 0.912319  [595264/984410]
loss: 0.632063  [601664/984410]
loss: 1.046883  [608064/984410]
loss: 0.867553  [614464/984410]
loss: 0.814396  [620864/984410]
loss: 0.964585  [627264/984410]
loss: 0.703321  [633664/984410]
loss: 0.917907  [640064/984410]
loss: 0.909228  [646464/984410]
loss: 0.824079  [652864/984410]
loss: 0.614558  [659264/984410]
loss: 0.866985  [665664/984410]
loss: 0.729121  [672064/984410]
loss: 0.672111  [678464/984410]
loss: 0.537827  [684864/984410]
loss: 0.748996  [691264/984410]
loss: 0.580633  [697664/984410]
loss: 0.871724  [704064/984410]
loss: 0.768637  [710464/984410]
loss: 0.796849  [716864/984410]
loss: 0.800834  [723264/984410]
loss: 0.685309  [729664/984410]
loss: 0.692164  [736064/984410]
loss: 0.882211  [742464/984410]
loss: 0.844529  [748864/984410]
loss: 0.844446  [755264/984410]
loss: 0.798679  [761664/984410]
loss: 0.814164  [768064/984410]
loss: 0.860556  [774464/984410]
loss: 0.687764  [780864/984410]
loss: 0.603297  [787264/984410]
loss: 0.578476  [793664/984410]
loss: 0.848140  [800064/984410]
loss: 0.760598  [806464/984410]
loss: 0.689776  [812864/984410]
loss: 0.578057  [819264/984410]
loss: 1.050738  [825664/984410]
loss: 0.838193  [832064/984410]
loss: 0.783487  [838464/984410]
loss: 0.940030  [844864/984410]
loss: 0.790960  [851264/984410]
loss: 0.681353  [857664/984410]
loss: 0.872959  [864064/984410]
loss: 0.790909  [870464/984410]
loss: 0.873363  [876864/984410]
loss: 0.677266  [883264/984410]
loss: 0.637409  [889664/984410]
loss: 0.610558  [896064/984410]
loss: 0.766645  [902464/984410]
loss: 1.093673  [908864/984410]
loss: 0.747324  [915264/984410]
loss: 0.864567  [921664/984410]
loss: 0.719639  [928064/984410]
loss: 0.677901  [934464/984410]
loss: 0.926014  [940864/984410]
loss: 0.685916  [947264/984410]
loss: 0.798673  [953664/984410]
loss: 0.581746  [960064/984410]
loss: 0.601614  [966464/984410]
loss: 0.860212  [972864/984410]
loss: 0.817323  [979264/984410]
Epoch 1/3, Training Loss (epoch average): 0.8534, Test Loss: 0.9341, Test Accuracy: 69.32%
loss: 0.670528  [   64/984410]
loss: 0.697959  [ 6464/984410]
loss: 0.652194  [12864/984410]
loss: 0.542930  [19264/984410]
loss: 0.595838  [25664/984410]
loss: 0.549914  [32064/984410]
loss: 0.805697  [38464/984410]
loss: 0.518107  [44864/984410]
loss: 0.569326  [51264/984410]
loss: 0.734332  [57664/984410]
loss: 0.854623  [64064/984410]
loss: 0.637450  [70464/984410]
loss: 0.594229  [76864/984410]
loss: 0.729868  [83264/984410]
loss: 0.489851  [89664/984410]
loss: 0.652655  [96064/984410]
loss: 0.642986  [102464/984410]
loss: 0.532637  [108864/984410]
loss: 0.901091  [115264/984410]
loss: 0.605589  [121664/984410]
loss: 0.567213  [128064/984410]
loss: 0.580376  [134464/984410]
loss: 0.563686  [140864/984410]
loss: 0.839681  [147264/984410]
loss: 0.596721  [153664/984410]
loss: 0.354225  [160064/984410]
loss: 0.623543  [166464/984410]
loss: 0.769785  [172864/984410]
loss: 0.670475  [179264/984410]
loss: 0.737526  [185664/984410]
loss: 0.705192  [192064/984410]
loss: 0.675497  [198464/984410]
loss: 0.695557  [204864/984410]
loss: 0.860362  [211264/984410]
loss: 0.666219  [217664/984410]
loss: 0.473488  [224064/984410]
loss: 0.518491  [230464/984410]
loss: 0.553953  [236864/984410]
loss: 0.563555  [243264/984410]
loss: 0.644590  [249664/984410]
loss: 0.733339  [256064/984410]
loss: 0.904437  [262464/984410]
loss: 0.689704  [268864/984410]
loss: 0.582858  [275264/984410]
loss: 0.547792  [281664/984410]
loss: 0.578482  [288064/984410]
loss: 1.054577  [294464/984410]
loss: 0.757438  [300864/984410]
loss: 0.773262  [307264/984410]
loss: 0.732174  [313664/984410]
loss: 0.634313  [320064/984410]
loss: 0.744336  [326464/984410]
loss: 0.869709  [332864/984410]
loss: 0.772234  [339264/984410]
loss: 0.730640  [345664/984410]
loss: 0.709866  [352064/984410]
loss: 0.706429  [358464/984410]
loss: 0.758415  [364864/984410]
loss: 0.582366  [371264/984410]
loss: 0.790513  [377664/984410]
loss: 0.753750  [384064/984410]
loss: 0.742254  [390464/984410]
loss: 0.687588  [396864/984410]
loss: 0.622156  [403264/984410]
loss: 0.412934  [409664/984410]
loss: 0.527507  [416064/984410]
loss: 0.810427  [422464/984410]
loss: 0.863726  [428864/984410]
loss: 0.487845  [435264/984410]
loss: 0.603931  [441664/984410]
loss: 0.430742  [448064/984410]
loss: 0.633236  [454464/984410]
loss: 0.601649  [460864/984410]
loss: 0.522896  [467264/984410]
loss: 0.800819  [473664/984410]
loss: 0.443540  [480064/984410]
loss: 0.569608  [486464/984410]
loss: 0.624507  [492864/984410]
loss: 0.580709  [499264/984410]
loss: 0.720014  [505664/984410]
loss: 0.515736  [512064/984410]
loss: 0.611078  [518464/984410]
loss: 0.567133  [524864/984410]
loss: 0.782127  [531264/984410]
loss: 0.837097  [537664/984410]
loss: 0.531865  [544064/984410]
loss: 1.073589  [550464/984410]
loss: 0.628810  [556864/984410]
loss: 0.830713  [563264/984410]
loss: 0.548166  [569664/984410]
loss: 0.962958  [576064/984410]
loss: 0.585213  [582464/984410]
loss: 0.604211  [588864/984410]
loss: 0.734630  [595264/984410]
loss: 0.824290  [601664/984410]
loss: 0.575366  [608064/984410]
loss: 0.797528  [614464/984410]
loss: 0.720992  [620864/984410]
loss: 0.752109  [627264/984410]
loss: 0.675898  [633664/984410]
loss: 0.707548  [640064/984410]
loss: 0.432188  [646464/984410]
loss: 0.876686  [652864/984410]
loss: 0.794378  [659264/984410]
loss: 0.830466  [665664/984410]
loss: 0.694503  [672064/984410]
loss: 0.639454  [678464/984410]
loss: 0.910047  [684864/984410]
loss: 0.785046  [691264/984410]
loss: 0.868022  [697664/984410]
loss: 0.666375  [704064/984410]
loss: 0.836481  [710464/984410]
loss: 0.500878  [716864/984410]
loss: 0.864074  [723264/984410]
loss: 0.733905  [729664/984410]
loss: 0.809236  [736064/984410]
loss: 0.643011  [742464/984410]
loss: 0.603895  [748864/984410]
loss: 0.591054  [755264/984410]
loss: 0.571657  [761664/984410]
loss: 0.783546  [768064/984410]
loss: 0.664155  [774464/984410]
loss: 0.451268  [780864/984410]
loss: 0.753474  [787264/984410]
loss: 0.741555  [793664/984410]
loss: 0.548365  [800064/984410]
loss: 0.533207  [806464/984410]
loss: 0.820209  [812864/984410]
loss: 0.721940  [819264/984410]
loss: 0.792946  [825664/984410]
loss: 0.524886  [832064/984410]
loss: 0.578996  [838464/984410]
loss: 0.696660  [844864/984410]
loss: 0.746197  [851264/984410]
loss: 0.842011  [857664/984410]
loss: 0.919754  [864064/984410]
loss: 0.899225  [870464/984410]
loss: 0.729813  [876864/984410]
loss: 0.623309  [883264/984410]
loss: 0.857390  [889664/984410]
loss: 0.659263  [896064/984410]
loss: 0.619021  [902464/984410]
loss: 0.696707  [908864/984410]
loss: 0.626481  [915264/984410]
loss: 0.656682  [921664/984410]
loss: 0.788332  [928064/984410]
loss: 0.790657  [934464/984410]
loss: 0.809111  [940864/984410]
loss: 0.683228  [947264/984410]
loss: 0.410783  [953664/984410]
loss: 0.629139  [960064/984410]
loss: 0.725798  [966464/984410]
loss: 0.468401  [972864/984410]
loss: 0.504455  [979264/984410]
Epoch 2/3, Training Loss (epoch average): 0.6926, Test Loss: 0.9259, Test Accuracy: 68.66%
loss: 0.633440  [   64/984410]
loss: 0.525251  [ 6464/984410]
loss: 0.678459  [12864/984410]
loss: 0.606717  [19264/984410]
loss: 0.677749  [25664/984410]
loss: 0.355734  [32064/984410]
loss: 0.547705  [38464/984410]
loss: 0.397989  [44864/984410]
loss: 0.434325  [51264/984410]
loss: 0.513912  [57664/984410]
loss: 0.485198  [64064/984410]
loss: 0.775243  [70464/984410]
loss: 0.674885  [76864/984410]
loss: 0.819067  [83264/984410]
loss: 0.623519  [89664/984410]
loss: 0.605800  [96064/984410]
loss: 0.684438  [102464/984410]
loss: 0.581031  [108864/984410]
loss: 0.660898  [115264/984410]
loss: 0.515212  [121664/984410]
loss: 0.419479  [128064/984410]
loss: 0.755395  [134464/984410]
loss: 0.634513  [140864/984410]
loss: 0.649880  [147264/984410]
loss: 0.423985  [153664/984410]
loss: 0.637204  [160064/984410]
loss: 0.591923  [166464/984410]
loss: 0.386746  [172864/984410]
loss: 0.472190  [179264/984410]
loss: 0.651749  [185664/984410]
loss: 0.650073  [192064/984410]
loss: 0.582339  [198464/984410]
loss: 0.466067  [204864/984410]
loss: 0.803259  [211264/984410]
loss: 0.692431  [217664/984410]
loss: 0.601803  [224064/984410]
loss: 0.557954  [230464/984410]
loss: 0.547677  [236864/984410]
loss: 0.489599  [243264/984410]
loss: 0.712471  [249664/984410]
loss: 0.588063  [256064/984410]
loss: 0.619318  [262464/984410]
loss: 0.512184  [268864/984410]
loss: 0.676275  [275264/984410]
loss: 0.578298  [281664/984410]
loss: 0.863680  [288064/984410]
loss: 0.800593  [294464/984410]
loss: 0.787538  [300864/984410]
loss: 0.714127  [307264/984410]
loss: 0.809715  [313664/984410]
loss: 0.550999  [320064/984410]
loss: 0.615515  [326464/984410]
loss: 0.633590  [332864/984410]
loss: 0.597973  [339264/984410]
loss: 0.613214  [345664/984410]
loss: 0.798011  [352064/984410]
loss: 0.504765  [358464/984410]
loss: 0.616344  [364864/984410]
loss: 0.622722  [371264/984410]
loss: 0.789570  [377664/984410]
loss: 0.643378  [384064/984410]
loss: 0.728944  [390464/984410]
loss: 0.717063  [396864/984410]
loss: 0.799885  [403264/984410]
loss: 0.620207  [409664/984410]
loss: 0.526901  [416064/984410]
loss: 0.481145  [422464/984410]
loss: 0.592028  [428864/984410]
loss: 0.932944  [435264/984410]
loss: 0.554457  [441664/984410]
loss: 0.619674  [448064/984410]
loss: 0.503063  [454464/984410]
loss: 1.020231  [460864/984410]
loss: 0.614691  [467264/984410]
loss: 0.874874  [473664/984410]
loss: 0.907690  [480064/984410]
loss: 0.649313  [486464/984410]
loss: 0.613868  [492864/984410]
loss: 0.905136  [499264/984410]
loss: 0.876698  [505664/984410]
loss: 0.636553  [512064/984410]
loss: 0.805148  [518464/984410]
loss: 0.737021  [524864/984410]
loss: 0.526326  [531264/984410]
loss: 0.966729  [537664/984410]
loss: 0.601288  [544064/984410]
loss: 0.440740  [550464/984410]
loss: 0.571341  [556864/984410]
loss: 0.592584  [563264/984410]
loss: 0.415012  [569664/984410]
loss: 0.573838  [576064/984410]
loss: 0.518008  [582464/984410]
loss: 0.859112  [588864/984410]
loss: 0.748566  [595264/984410]
loss: 0.835374  [601664/984410]
loss: 0.596596  [608064/984410]
loss: 0.834752  [614464/984410]
loss: 0.798622  [620864/984410]
loss: 0.501794  [627264/984410]
loss: 0.503431  [633664/984410]
loss: 0.370271  [640064/984410]
loss: 0.497947  [646464/984410]
loss: 0.820083  [652864/984410]
loss: 0.418852  [659264/984410]
loss: 0.516204  [665664/984410]
loss: 0.796616  [672064/984410]
loss: 1.022707  [678464/984410]
loss: 0.441277  [684864/984410]
loss: 0.763491  [691264/984410]
loss: 0.618723  [697664/984410]
loss: 0.535609  [704064/984410]
loss: 1.157692  [710464/984410]
loss: 0.668426  [716864/984410]
loss: 0.549522  [723264/984410]
loss: 0.413898  [729664/984410]
loss: 0.576481  [736064/984410]
loss: 0.627866  [742464/984410]
loss: 0.568047  [748864/984410]
loss: 0.478147  [755264/984410]
loss: 0.710958  [761664/984410]
loss: 0.494923  [768064/984410]
loss: 0.457132  [774464/984410]
loss: 0.754483  [780864/984410]
loss: 0.777387  [787264/984410]
loss: 0.767983  [793664/984410]
loss: 0.784574  [800064/984410]
loss: 0.470337  [806464/984410]
loss: 0.463171  [812864/984410]
loss: 0.721740  [819264/984410]
loss: 0.784005  [825664/984410]
loss: 0.800083  [832064/984410]
loss: 0.790757  [838464/984410]
loss: 0.797618  [844864/984410]
loss: 0.957384  [851264/984410]
loss: 0.546130  [857664/984410]
loss: 0.763956  [864064/984410]
loss: 0.794125  [870464/984410]
loss: 0.597996  [876864/984410]
loss: 0.784587  [883264/984410]
loss: 0.638594  [889664/984410]
loss: 0.499518  [896064/984410]
loss: 0.687322  [902464/984410]
loss: 0.369118  [908864/984410]
loss: 0.812303  [915264/984410]
loss: 0.732899  [921664/984410]
loss: 0.621542  [928064/984410]
loss: 0.518395  [934464/984410]
loss: 0.431831  [940864/984410]
loss: 0.932472  [947264/984410]
loss: 0.595109  [953664/984410]
loss: 0.648750  [960064/984410]
loss: 0.695130  [966464/984410]
loss: 0.696214  [972864/984410]
loss: 0.615091  [979264/984410]
Epoch 3/3, Training Loss (epoch average): 0.6395, Test Loss: 0.9946, Test Accuracy: 66.82%
The loss curve has been saved as 'training_plots/loss_curve_20250328-130304.png'.
