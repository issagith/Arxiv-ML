starting training with the following hyperparams :
vocab_size : 13384
embedding_dim : 64
hidden_dim : 512
num_classes : 138
num_hidden_layers : 1


loss: 4.918238  [   64/108954]
loss: 1.938690  [ 6464/108954]
loss: 1.659287  [12864/108954]
loss: 1.794191  [19264/108954]
loss: 1.457497  [25664/108954]
loss: 1.651053  [32064/108954]
loss: 1.206571  [38464/108954]
loss: 1.810537  [44864/108954]
loss: 1.623066  [51264/108954]
loss: 1.683776  [57664/108954]
loss: 1.207613  [64064/108954]
loss: 1.363439  [70464/108954]
loss: 1.865980  [76864/108954]
loss: 1.496917  [83264/108954]
loss: 1.683653  [89664/108954]
loss: 1.471409  [96064/108954]
loss: 1.827833  [102464/108954]
loss: 1.668196  [108864/108954]
Epoch 1/10, Training Loss (epoch average): 1.6462, Test Loss: 1.4078, Test Accuracy: 61.81%
loss: 1.030163  [   64/108954]
loss: 1.248233  [ 6464/108954]
loss: 1.746335  [12864/108954]
loss: 1.272392  [19264/108954]
loss: 1.139114  [25664/108954]
loss: 1.349896  [32064/108954]
loss: 1.610320  [38464/108954]
loss: 0.814795  [44864/108954]
loss: 1.308651  [51264/108954]
loss: 1.093786  [57664/108954]
loss: 1.169537  [64064/108954]
loss: 1.417135  [70464/108954]
loss: 1.229491  [76864/108954]
loss: 1.522065  [83264/108954]
loss: 1.349304  [89664/108954]
loss: 1.230405  [96064/108954]
loss: 1.131820  [102464/108954]
loss: 1.454266  [108864/108954]
Epoch 2/10, Training Loss (epoch average): 1.2653, Test Loss: 1.2979, Test Accuracy: 64.53%
loss: 1.388251  [   64/108954]
loss: 1.085660  [ 6464/108954]
loss: 0.950616  [12864/108954]
loss: 0.836419  [19264/108954]
loss: 0.832103  [25664/108954]
loss: 1.056434  [32064/108954]
loss: 1.192302  [38464/108954]
loss: 1.155192  [44864/108954]
loss: 1.017375  [51264/108954]
loss: 1.213950  [57664/108954]
loss: 0.995240  [64064/108954]
loss: 1.063027  [70464/108954]
loss: 0.826759  [76864/108954]
loss: 1.350145  [83264/108954]
loss: 1.311954  [89664/108954]
loss: 0.867711  [96064/108954]
loss: 1.245584  [102464/108954]
loss: 1.401659  [108864/108954]
Epoch 3/10, Training Loss (epoch average): 1.1341, Test Loss: 1.2548, Test Accuracy: 65.37%
loss: 0.906079  [   64/108954]
loss: 1.190460  [ 6464/108954]
loss: 1.050548  [12864/108954]
loss: 0.971795  [19264/108954]
loss: 1.345690  [25664/108954]
loss: 1.066718  [32064/108954]
loss: 1.306115  [38464/108954]
loss: 0.954371  [44864/108954]
loss: 1.168614  [51264/108954]
loss: 1.196565  [57664/108954]
loss: 0.892589  [64064/108954]
loss: 1.053164  [70464/108954]
loss: 0.981544  [76864/108954]
loss: 1.061510  [83264/108954]
loss: 0.935108  [89664/108954]
loss: 0.916108  [96064/108954]
loss: 0.830872  [102464/108954]
loss: 1.226435  [108864/108954]
Epoch 4/10, Training Loss (epoch average): 1.0434, Test Loss: 1.2408, Test Accuracy: 65.98%
loss: 0.754155  [   64/108954]
loss: 0.697132  [ 6464/108954]
loss: 0.899610  [12864/108954]
loss: 0.754785  [19264/108954]
loss: 0.889609  [25664/108954]
loss: 0.887382  [32064/108954]
loss: 1.048923  [38464/108954]
loss: 0.784703  [44864/108954]
loss: 0.976899  [51264/108954]
loss: 1.091939  [57664/108954]
loss: 0.827127  [64064/108954]
loss: 0.988334  [70464/108954]
loss: 1.536502  [76864/108954]
loss: 0.922633  [83264/108954]
loss: 1.099466  [89664/108954]
loss: 1.049805  [96064/108954]
loss: 0.915610  [102464/108954]
loss: 0.952637  [108864/108954]
Epoch 5/10, Training Loss (epoch average): 0.9702, Test Loss: 1.2305, Test Accuracy: 66.17%
loss: 0.886735  [   64/108954]
loss: 1.385849  [ 6464/108954]
loss: 0.986735  [12864/108954]
loss: 1.044227  [19264/108954]
loss: 0.870615  [25664/108954]
loss: 0.810992  [32064/108954]
loss: 1.015499  [38464/108954]
loss: 0.948524  [44864/108954]
loss: 0.916066  [51264/108954]
loss: 0.892056  [57664/108954]
loss: 0.882726  [64064/108954]
loss: 0.889640  [70464/108954]
loss: 0.981652  [76864/108954]
loss: 1.168050  [83264/108954]
loss: 0.931631  [89664/108954]
loss: 0.717973  [96064/108954]
loss: 0.920714  [102464/108954]
loss: 0.834113  [108864/108954]
Epoch 6/10, Training Loss (epoch average): 0.9048, Test Loss: 1.2354, Test Accuracy: 66.44%
loss: 0.741997  [   64/108954]
loss: 0.989103  [ 6464/108954]
loss: 0.647159  [12864/108954]
loss: 0.722739  [19264/108954]
loss: 0.755187  [25664/108954]
loss: 0.738169  [32064/108954]
loss: 0.732752  [38464/108954]
loss: 0.881292  [44864/108954]
loss: 0.951525  [51264/108954]
loss: 0.828800  [57664/108954]
loss: 1.047892  [64064/108954]
loss: 0.679155  [70464/108954]
loss: 0.876385  [76864/108954]
loss: 0.877727  [83264/108954]
loss: 0.810100  [89664/108954]
loss: 0.775899  [96064/108954]
loss: 0.960157  [102464/108954]
loss: 0.683252  [108864/108954]
Epoch 7/10, Training Loss (epoch average): 0.8479, Test Loss: 1.2585, Test Accuracy: 66.00%
loss: 0.922428  [   64/108954]
loss: 0.865796  [ 6464/108954]
loss: 0.920111  [12864/108954]
loss: 0.687130  [19264/108954]
loss: 0.872785  [25664/108954]
loss: 0.709489  [32064/108954]
loss: 0.880376  [38464/108954]
loss: 0.925030  [44864/108954]
loss: 0.725806  [51264/108954]
loss: 0.872070  [57664/108954]
loss: 0.884510  [64064/108954]
loss: 0.616457  [70464/108954]
loss: 0.671118  [76864/108954]
loss: 0.729911  [83264/108954]
loss: 0.890853  [89664/108954]
loss: 0.722126  [96064/108954]
loss: 0.866244  [102464/108954]
loss: 1.029960  [108864/108954]
Epoch 8/10, Training Loss (epoch average): 0.7943, Test Loss: 1.2876, Test Accuracy: 66.13%
loss: 0.880719  [   64/108954]
loss: 0.631891  [ 6464/108954]
loss: 0.590872  [12864/108954]
loss: 0.813138  [19264/108954]
loss: 0.741960  [25664/108954]
loss: 0.554867  [32064/108954]
loss: 1.044639  [38464/108954]
loss: 0.789640  [44864/108954]
loss: 0.870768  [51264/108954]
loss: 0.779938  [57664/108954]
loss: 0.712237  [64064/108954]
loss: 0.684128  [70464/108954]
loss: 0.756295  [76864/108954]
loss: 0.765543  [83264/108954]
loss: 0.849227  [89664/108954]
loss: 0.891803  [96064/108954]
loss: 0.906205  [102464/108954]
loss: 0.916821  [108864/108954]
Epoch 9/10, Training Loss (epoch average): 0.7454, Test Loss: 1.3140, Test Accuracy: 66.18%
loss: 0.669778  [   64/108954]
loss: 0.753168  [ 6464/108954]
loss: 0.558969  [12864/108954]
loss: 0.626156  [19264/108954]
loss: 0.689554  [25664/108954]
loss: 0.695351  [32064/108954]
loss: 0.670082  [38464/108954]
loss: 0.597968  [44864/108954]
loss: 0.540186  [51264/108954]
loss: 0.687659  [57664/108954]
loss: 0.780600  [64064/108954]
loss: 0.681412  [70464/108954]
loss: 0.978957  [76864/108954]
loss: 0.639041  [83264/108954]
loss: 0.677751  [89664/108954]
loss: 0.868700  [96064/108954]
loss: 0.731178  [102464/108954]
loss: 0.768995  [108864/108954]
Epoch 10/10, Training Loss (epoch average): 0.6964, Test Loss: 1.3574, Test Accuracy: 66.06%
The loss curve has been saved as 'training_plots/loss_curve_20250310-114044.png'.
