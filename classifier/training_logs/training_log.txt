loading projection weights from data\word2vec-google-news-300.bin
KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from data\\word2vec-google-news-300.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2025-03-28T16:02:15.680711', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'}
loss: 3.018606  [   64/984410]
loss: 1.839006  [ 6464/984410]
loss: 1.215902  [12864/984410]
loss: 1.262496  [19264/984410]
loss: 1.133054  [25664/984410]
loss: 1.179577  [32064/984410]
loss: 1.108701  [38464/984410]
loss: 1.470014  [44864/984410]
loss: 1.234395  [51264/984410]
loss: 0.870168  [57664/984410]
loss: 1.411572  [64064/984410]
loss: 1.117830  [70464/984410]
loss: 0.898016  [76864/984410]
loss: 0.878159  [83264/984410]
loss: 0.947360  [89664/984410]
loss: 1.004353  [96064/984410]
loss: 0.897698  [102464/984410]
loss: 0.962750  [108864/984410]
loss: 0.935666  [115264/984410]
loss: 0.854902  [121664/984410]
loss: 0.736692  [128064/984410]
loss: 1.077961  [134464/984410]
loss: 1.402152  [140864/984410]
loss: 0.978874  [147264/984410]
loss: 0.700133  [153664/984410]
loss: 0.839839  [160064/984410]
loss: 0.907085  [166464/984410]
loss: 0.986872  [172864/984410]
loss: 0.756744  [179264/984410]
loss: 0.820954  [185664/984410]
loss: 0.864705  [192064/984410]
loss: 0.655509  [198464/984410]
loss: 0.710054  [204864/984410]
loss: 0.992981  [211264/984410]
loss: 0.914843  [217664/984410]
loss: 1.001905  [224064/984410]
loss: 1.065722  [230464/984410]
loss: 0.948128  [236864/984410]
loss: 1.024799  [243264/984410]
loss: 0.747063  [249664/984410]
loss: 0.743275  [256064/984410]
loss: 0.926326  [262464/984410]
loss: 0.965746  [268864/984410]
loss: 0.642529  [275264/984410]
loss: 0.928673  [281664/984410]
loss: 0.618331  [288064/984410]
loss: 0.936574  [294464/984410]
loss: 0.966405  [300864/984410]
loss: 1.160826  [307264/984410]
loss: 0.872002  [313664/984410]
loss: 0.854184  [320064/984410]
loss: 0.793537  [326464/984410]
loss: 0.949737  [332864/984410]
loss: 0.710210  [339264/984410]
loss: 0.976138  [345664/984410]
loss: 0.838119  [352064/984410]
loss: 0.635579  [358464/984410]
loss: 0.597167  [364864/984410]
loss: 0.594667  [371264/984410]
loss: 0.634863  [377664/984410]
loss: 0.905838  [384064/984410]
loss: 0.862380  [390464/984410]
loss: 0.735463  [396864/984410]
loss: 0.787530  [403264/984410]
loss: 0.665161  [409664/984410]
loss: 0.917164  [416064/984410]
loss: 0.686179  [422464/984410]
loss: 0.752643  [428864/984410]
loss: 0.691696  [435264/984410]
loss: 0.853064  [441664/984410]
loss: 0.773059  [448064/984410]
loss: 0.826028  [454464/984410]
loss: 0.911741  [460864/984410]
loss: 0.759942  [467264/984410]
loss: 0.759422  [473664/984410]
loss: 0.772502  [480064/984410]
loss: 0.731400  [486464/984410]
loss: 0.504856  [492864/984410]
loss: 0.891291  [499264/984410]
loss: 1.012174  [505664/984410]
loss: 0.820035  [512064/984410]
loss: 1.164329  [518464/984410]
loss: 0.816141  [524864/984410]
loss: 0.824792  [531264/984410]
loss: 0.759469  [537664/984410]
loss: 0.562220  [544064/984410]
loss: 0.796182  [550464/984410]
loss: 0.757139  [556864/984410]
loss: 0.806058  [563264/984410]
loss: 0.646172  [569664/984410]
loss: 0.945412  [576064/984410]
loss: 0.757421  [582464/984410]
loss: 0.853699  [588864/984410]
loss: 0.639569  [595264/984410]
loss: 0.958610  [601664/984410]
loss: 0.905764  [608064/984410]
loss: 0.534018  [614464/984410]
loss: 0.760393  [620864/984410]
loss: 0.698464  [627264/984410]
loss: 0.481861  [633664/984410]
loss: 0.837233  [640064/984410]
loss: 0.658304  [646464/984410]
loss: 0.588104  [652864/984410]
loss: 0.720178  [659264/984410]
loss: 0.598301  [665664/984410]
loss: 0.865947  [672064/984410]
loss: 0.883881  [678464/984410]
loss: 0.618686  [684864/984410]
loss: 0.520770  [691264/984410]
loss: 0.616347  [697664/984410]
loss: 0.620990  [704064/984410]
loss: 0.648759  [710464/984410]
loss: 0.770804  [716864/984410]
loss: 0.585797  [723264/984410]
loss: 0.701312  [729664/984410]
loss: 0.772760  [736064/984410]
loss: 0.879184  [742464/984410]
loss: 0.582465  [748864/984410]
loss: 0.874997  [755264/984410]
loss: 0.644697  [761664/984410]
loss: 0.844435  [768064/984410]
loss: 0.766356  [774464/984410]
loss: 0.699279  [780864/984410]
loss: 0.672150  [787264/984410]
loss: 0.972617  [793664/984410]
loss: 0.895628  [800064/984410]
loss: 0.741314  [806464/984410]
loss: 0.778618  [812864/984410]
loss: 0.979590  [819264/984410]
loss: 0.729618  [825664/984410]
loss: 0.774910  [832064/984410]
loss: 0.905006  [838464/984410]
loss: 0.419132  [844864/984410]
loss: 0.768592  [851264/984410]
loss: 0.744302  [857664/984410]
loss: 0.768613  [864064/984410]
loss: 0.872176  [870464/984410]
loss: 0.759045  [876864/984410]
loss: 0.961251  [883264/984410]
loss: 0.723170  [889664/984410]
loss: 0.799338  [896064/984410]
loss: 0.666217  [902464/984410]
loss: 0.596586  [908864/984410]
loss: 0.828166  [915264/984410]
loss: 0.801755  [921664/984410]
loss: 0.635507  [928064/984410]
loss: 0.558646  [934464/984410]
loss: 0.565364  [940864/984410]
loss: 0.595904  [947264/984410]
loss: 0.543252  [953664/984410]
loss: 0.745423  [960064/984410]
loss: 0.606529  [966464/984410]
loss: 0.661305  [972864/984410]
loss: 0.606991  [979264/984410]
Epoch 1/3, Training Loss (epoch average): 0.8198, Test Loss: 0.8955, Test Accuracy: 69.98%
loss: 0.525599  [   64/984410]
loss: 0.595922  [ 6464/984410]
loss: 0.783814  [12864/984410]
loss: 0.522562  [19264/984410]
loss: 0.729438  [25664/984410]
loss: 0.758951  [32064/984410]
loss: 0.599001  [38464/984410]
loss: 0.656209  [44864/984410]
loss: 0.879170  [51264/984410]
loss: 0.554587  [57664/984410]
loss: 0.495062  [64064/984410]
loss: 1.071839  [70464/984410]
loss: 0.661111  [76864/984410]
loss: 0.519939  [83264/984410]
loss: 0.659494  [89664/984410]
loss: 0.551818  [96064/984410]
loss: 0.602923  [102464/984410]
loss: 0.664051  [108864/984410]
loss: 0.397492  [115264/984410]
loss: 0.480170  [121664/984410]
loss: 0.690672  [128064/984410]
loss: 0.519598  [134464/984410]
loss: 0.616136  [140864/984410]
loss: 0.568301  [147264/984410]
loss: 0.763021  [153664/984410]
loss: 0.709793  [160064/984410]
loss: 0.692839  [166464/984410]
loss: 0.620169  [172864/984410]
loss: 0.693703  [179264/984410]
loss: 0.405400  [185664/984410]
loss: 0.588366  [192064/984410]
loss: 0.658418  [198464/984410]
loss: 0.536003  [204864/984410]
loss: 0.747313  [211264/984410]
loss: 0.836414  [217664/984410]
loss: 0.546044  [224064/984410]
loss: 0.435341  [230464/984410]
loss: 0.580098  [236864/984410]
loss: 0.487605  [243264/984410]
loss: 1.013617  [249664/984410]
loss: 0.819550  [256064/984410]
loss: 0.759326  [262464/984410]
loss: 0.497541  [268864/984410]
loss: 0.618580  [275264/984410]
loss: 0.755775  [281664/984410]
loss: 0.564021  [288064/984410]
loss: 0.972757  [294464/984410]
loss: 0.551625  [300864/984410]
loss: 0.668873  [307264/984410]
loss: 0.470836  [313664/984410]
loss: 0.742510  [320064/984410]
loss: 0.720591  [326464/984410]
loss: 0.518617  [332864/984410]
loss: 0.510331  [339264/984410]
loss: 0.805083  [345664/984410]
loss: 0.539757  [352064/984410]
loss: 0.676466  [358464/984410]
loss: 0.671867  [364864/984410]
loss: 0.545203  [371264/984410]
loss: 0.630328  [377664/984410]
loss: 0.924760  [384064/984410]
loss: 0.497672  [390464/984410]
loss: 0.666748  [396864/984410]
loss: 0.700255  [403264/984410]
loss: 0.579625  [409664/984410]
loss: 0.859053  [416064/984410]
loss: 0.809260  [422464/984410]
loss: 0.735301  [428864/984410]
loss: 0.775461  [435264/984410]
loss: 0.514898  [441664/984410]
loss: 0.506779  [448064/984410]
loss: 0.644674  [454464/984410]
loss: 0.431575  [460864/984410]
loss: 0.676753  [467264/984410]
loss: 0.591803  [473664/984410]
loss: 0.514421  [480064/984410]
loss: 0.610403  [486464/984410]
loss: 0.475457  [492864/984410]
loss: 0.823938  [499264/984410]
loss: 0.595945  [505664/984410]
loss: 0.641399  [512064/984410]
loss: 0.677054  [518464/984410]
loss: 0.747795  [524864/984410]
loss: 0.666790  [531264/984410]
loss: 0.362409  [537664/984410]
loss: 0.889048  [544064/984410]
loss: 0.635074  [550464/984410]
loss: 0.878131  [556864/984410]
loss: 0.815891  [563264/984410]
loss: 0.863478  [569664/984410]
loss: 0.459823  [576064/984410]
loss: 0.806773  [582464/984410]
loss: 0.790240  [588864/984410]
loss: 1.005553  [595264/984410]
loss: 0.601077  [601664/984410]
loss: 0.634014  [608064/984410]
loss: 0.621883  [614464/984410]
loss: 0.546823  [620864/984410]
loss: 0.700534  [627264/984410]
loss: 0.586517  [633664/984410]
loss: 0.643564  [640064/984410]
loss: 0.868858  [646464/984410]
loss: 0.557487  [652864/984410]
loss: 0.699433  [659264/984410]
loss: 0.825950  [665664/984410]
loss: 0.663288  [672064/984410]
loss: 0.767766  [678464/984410]
loss: 0.794694  [684864/984410]
loss: 0.678137  [691264/984410]
loss: 0.803605  [697664/984410]
loss: 0.818020  [704064/984410]
loss: 0.541273  [710464/984410]
loss: 0.877634  [716864/984410]
loss: 0.437247  [723264/984410]
loss: 0.651579  [729664/984410]
loss: 0.587937  [736064/984410]
loss: 0.707978  [742464/984410]
loss: 0.675163  [748864/984410]
loss: 0.639562  [755264/984410]
loss: 0.605989  [761664/984410]
loss: 0.754840  [768064/984410]
loss: 0.687485  [774464/984410]
loss: 0.876488  [780864/984410]
loss: 0.695568  [787264/984410]
loss: 0.431101  [793664/984410]
loss: 0.598641  [800064/984410]
loss: 0.657665  [806464/984410]
loss: 0.524872  [812864/984410]
loss: 0.829710  [819264/984410]
loss: 0.599956  [825664/984410]
loss: 0.630230  [832064/984410]
loss: 0.539798  [838464/984410]
loss: 0.709478  [844864/984410]
loss: 0.744749  [851264/984410]
loss: 0.847412  [857664/984410]
loss: 1.061024  [864064/984410]
loss: 0.652781  [870464/984410]
loss: 0.511655  [876864/984410]
loss: 0.856815  [883264/984410]
loss: 0.820331  [889664/984410]
loss: 0.543526  [896064/984410]
loss: 0.533578  [902464/984410]
loss: 0.489560  [908864/984410]
loss: 0.573282  [915264/984410]
loss: 0.668307  [921664/984410]
loss: 1.013533  [928064/984410]
loss: 0.627157  [934464/984410]
loss: 0.403563  [940864/984410]
loss: 0.691855  [947264/984410]
loss: 0.859639  [953664/984410]
loss: 0.468663  [960064/984410]
loss: 0.482155  [966464/984410]
loss: 0.683165  [972864/984410]
loss: 0.656280  [979264/984410]
Epoch 2/3, Training Loss (epoch average): 0.6407, Test Loss: 0.8402, Test Accuracy: 71.99%
loss: 0.727510  [   64/984410]
loss: 0.405632  [ 6464/984410]
loss: 0.733245  [12864/984410]
loss: 0.279511  [19264/984410]
loss: 0.217454  [25664/984410]
loss: 0.441583  [32064/984410]
loss: 0.448531  [38464/984410]
loss: 0.469652  [44864/984410]
loss: 0.604165  [51264/984410]
loss: 0.763251  [57664/984410]
loss: 0.637032  [64064/984410]
loss: 0.514071  [70464/984410]
loss: 0.581191  [76864/984410]
loss: 0.584064  [83264/984410]
loss: 0.464430  [89664/984410]
loss: 0.718368  [96064/984410]
loss: 0.572030  [102464/984410]
loss: 0.527024  [108864/984410]
loss: 0.442994  [115264/984410]
loss: 0.527661  [121664/984410]
loss: 0.565811  [128064/984410]
loss: 0.398573  [134464/984410]
loss: 0.461973  [140864/984410]
loss: 0.489466  [147264/984410]
loss: 0.637156  [153664/984410]
loss: 0.514375  [160064/984410]
loss: 0.559571  [166464/984410]
loss: 0.627236  [172864/984410]
loss: 0.512008  [179264/984410]
loss: 0.615526  [185664/984410]
loss: 0.431035  [192064/984410]
loss: 0.440498  [198464/984410]
loss: 0.491336  [204864/984410]
loss: 0.595272  [211264/984410]
loss: 0.498251  [217664/984410]
loss: 0.735143  [224064/984410]
loss: 0.364573  [230464/984410]
loss: 0.651542  [236864/984410]
loss: 0.578001  [243264/984410]
loss: 0.441116  [249664/984410]
loss: 0.413779  [256064/984410]
loss: 0.463608  [262464/984410]
loss: 0.544700  [268864/984410]
loss: 0.478627  [275264/984410]
loss: 0.338687  [281664/984410]
loss: 0.489174  [288064/984410]
loss: 0.593421  [294464/984410]
loss: 0.627364  [300864/984410]
loss: 0.516596  [307264/984410]
loss: 0.659315  [313664/984410]
loss: 0.444909  [320064/984410]
loss: 0.526111  [326464/984410]
loss: 0.630405  [332864/984410]
loss: 0.602863  [339264/984410]
loss: 0.475081  [345664/984410]
loss: 0.421780  [352064/984410]
loss: 0.416378  [358464/984410]
loss: 0.503258  [364864/984410]
loss: 0.458072  [371264/984410]
loss: 0.801344  [377664/984410]
loss: 0.680849  [384064/984410]
loss: 0.365138  [390464/984410]
loss: 0.467877  [396864/984410]
loss: 0.586446  [403264/984410]
loss: 0.539741  [409664/984410]
loss: 0.433072  [416064/984410]
loss: 0.647565  [422464/984410]
loss: 0.545894  [428864/984410]
loss: 0.677424  [435264/984410]
loss: 0.420014  [441664/984410]
loss: 0.602980  [448064/984410]
loss: 0.759740  [454464/984410]
loss: 0.467224  [460864/984410]
loss: 0.392664  [467264/984410]
loss: 0.590215  [473664/984410]
loss: 0.633522  [480064/984410]
loss: 0.597910  [486464/984410]
loss: 0.513110  [492864/984410]
loss: 0.514843  [499264/984410]
loss: 0.665583  [505664/984410]
loss: 0.527726  [512064/984410]
loss: 0.576623  [518464/984410]
loss: 0.502348  [524864/984410]
loss: 0.300747  [531264/984410]
loss: 0.409068  [537664/984410]
loss: 0.397820  [544064/984410]
loss: 0.692546  [550464/984410]
loss: 0.328252  [556864/984410]
loss: 0.593290  [563264/984410]
loss: 0.471704  [569664/984410]
loss: 0.581779  [576064/984410]
loss: 0.906000  [582464/984410]
loss: 0.598774  [588864/984410]
loss: 0.691509  [595264/984410]
loss: 0.831299  [601664/984410]
loss: 0.487192  [608064/984410]
loss: 0.875375  [614464/984410]
loss: 0.626932  [620864/984410]
loss: 0.516769  [627264/984410]
loss: 0.617428  [633664/984410]
loss: 0.574599  [640064/984410]
loss: 0.696997  [646464/984410]
loss: 0.528131  [652864/984410]
loss: 0.791481  [659264/984410]
loss: 0.964979  [665664/984410]
loss: 0.718578  [672064/984410]
loss: 0.327394  [678464/984410]
loss: 0.495706  [684864/984410]
loss: 0.562312  [691264/984410]
loss: 0.379944  [697664/984410]
loss: 0.589494  [704064/984410]
loss: 0.463064  [710464/984410]
loss: 0.686153  [716864/984410]
loss: 0.624295  [723264/984410]
loss: 0.636325  [729664/984410]
loss: 0.595484  [736064/984410]
loss: 0.538543  [742464/984410]
loss: 0.413794  [748864/984410]
loss: 0.575196  [755264/984410]
loss: 0.438396  [761664/984410]
loss: 0.764267  [768064/984410]
loss: 0.607670  [774464/984410]
loss: 0.619068  [780864/984410]
loss: 0.514113  [787264/984410]
loss: 0.492217  [793664/984410]
loss: 0.482822  [800064/984410]
loss: 0.562386  [806464/984410]
loss: 0.475470  [812864/984410]
loss: 0.507619  [819264/984410]
loss: 0.434111  [825664/984410]
loss: 0.530157  [832064/984410]
loss: 0.704690  [838464/984410]
loss: 0.431910  [844864/984410]
loss: 0.457191  [851264/984410]
loss: 0.565651  [857664/984410]
loss: 0.593703  [864064/984410]
loss: 0.652252  [870464/984410]
loss: 0.738765  [876864/984410]
loss: 0.600876  [883264/984410]
loss: 0.518348  [889664/984410]
loss: 0.311128  [896064/984410]
loss: 0.727613  [902464/984410]
loss: 0.688731  [908864/984410]
loss: 0.877602  [915264/984410]
loss: 0.428347  [921664/984410]
loss: 0.572989  [928064/984410]
loss: 0.350457  [934464/984410]
loss: 0.544179  [940864/984410]
loss: 0.500371  [947264/984410]
loss: 0.434585  [953664/984410]
loss: 0.474671  [960064/984410]
loss: 0.490088  [966464/984410]
loss: 0.513270  [972864/984410]
loss: 0.465935  [979264/984410]
Epoch 3/3, Training Loss (epoch average): 0.5517, Test Loss: 0.8798, Test Accuracy: 71.08%
The loss curve has been saved as 'training_plots/loss_curve_20250328-161848.png'.
