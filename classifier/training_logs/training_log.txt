loading projection weights from data\word2vec-google-news-300.bin
KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from data\\word2vec-google-news-300.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2025-03-28T16:45:59.589998', 'gensim': '4.3.3', 'python': '3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'}
loss: 2.925911  [   64/984410]
loss: 1.571862  [ 6464/984410]
loss: 1.580928  [12864/984410]
loss: 1.039726  [19264/984410]
loss: 1.281352  [25664/984410]
loss: 1.067031  [32064/984410]
loss: 1.116917  [38464/984410]
loss: 0.880496  [44864/984410]
loss: 0.956157  [51264/984410]
loss: 1.342111  [57664/984410]
loss: 1.056153  [64064/984410]
loss: 1.199095  [70464/984410]
loss: 0.819539  [76864/984410]
loss: 1.214000  [83264/984410]
loss: 0.787437  [89664/984410]
loss: 1.025969  [96064/984410]
loss: 0.738900  [102464/984410]
loss: 0.688921  [108864/984410]
loss: 0.724379  [115264/984410]
loss: 0.962896  [121664/984410]
loss: 0.782801  [128064/984410]
loss: 0.961885  [134464/984410]
loss: 1.125690  [140864/984410]
loss: 0.691615  [147264/984410]
loss: 0.948252  [153664/984410]
loss: 0.927037  [160064/984410]
loss: 0.901226  [166464/984410]
loss: 0.800121  [172864/984410]
loss: 0.697662  [179264/984410]
loss: 0.962481  [185664/984410]
loss: 0.790433  [192064/984410]
loss: 0.667521  [198464/984410]
loss: 0.785308  [204864/984410]
loss: 0.903835  [211264/984410]
loss: 1.339259  [217664/984410]
loss: 0.601706  [224064/984410]
loss: 0.698429  [230464/984410]
loss: 0.745999  [236864/984410]
loss: 0.765693  [243264/984410]
loss: 0.808549  [249664/984410]
loss: 0.949069  [256064/984410]
loss: 0.964169  [262464/984410]
loss: 0.749721  [268864/984410]
loss: 0.704551  [275264/984410]
loss: 0.804065  [281664/984410]
loss: 0.757619  [288064/984410]
loss: 0.573524  [294464/984410]
loss: 0.604148  [300864/984410]
loss: 0.873723  [307264/984410]
loss: 0.704844  [313664/984410]
loss: 0.680154  [320064/984410]
loss: 0.506581  [326464/984410]
loss: 0.936532  [332864/984410]
loss: 0.937616  [339264/984410]
loss: 0.592460  [345664/984410]
loss: 1.006904  [352064/984410]
loss: 0.869503  [358464/984410]
loss: 1.044473  [364864/984410]
loss: 0.680126  [371264/984410]
loss: 0.815701  [377664/984410]
loss: 0.794933  [384064/984410]
loss: 0.803224  [390464/984410]
loss: 0.661888  [396864/984410]
loss: 0.858455  [403264/984410]
loss: 0.982598  [409664/984410]
loss: 0.955459  [416064/984410]
loss: 1.000905  [422464/984410]
loss: 1.042932  [428864/984410]
loss: 0.743645  [435264/984410]
loss: 1.049437  [441664/984410]
loss: 0.748254  [448064/984410]
loss: 0.773350  [454464/984410]
loss: 0.767817  [460864/984410]
loss: 0.916600  [467264/984410]
loss: 0.821114  [473664/984410]
loss: 0.672406  [480064/984410]
loss: 0.773331  [486464/984410]
loss: 0.796738  [492864/984410]
loss: 0.996273  [499264/984410]
loss: 0.732465  [505664/984410]
loss: 0.853596  [512064/984410]
loss: 0.605904  [518464/984410]
loss: 0.707687  [524864/984410]
loss: 0.566565  [531264/984410]
loss: 0.667767  [537664/984410]
loss: 0.799044  [544064/984410]
loss: 0.453521  [550464/984410]
loss: 0.501962  [556864/984410]
loss: 0.652697  [563264/984410]
loss: 0.754111  [569664/984410]
loss: 0.730731  [576064/984410]
loss: 0.751947  [582464/984410]
loss: 0.977602  [588864/984410]
loss: 0.723811  [595264/984410]
loss: 0.799785  [601664/984410]
loss: 0.741128  [608064/984410]
loss: 0.713612  [614464/984410]
loss: 0.721500  [620864/984410]
loss: 1.016523  [627264/984410]
loss: 0.839610  [633664/984410]
loss: 0.535111  [640064/984410]
loss: 0.569292  [646464/984410]
loss: 0.791534  [652864/984410]
loss: 0.774230  [659264/984410]
loss: 0.811844  [665664/984410]
loss: 0.864090  [672064/984410]
loss: 0.511319  [678464/984410]
loss: 0.848372  [684864/984410]
loss: 0.864057  [691264/984410]
loss: 0.834460  [697664/984410]
loss: 0.700112  [704064/984410]
loss: 0.656190  [710464/984410]
loss: 0.429696  [716864/984410]
loss: 0.657708  [723264/984410]
loss: 0.818723  [729664/984410]
loss: 0.923917  [736064/984410]
loss: 0.596658  [742464/984410]
loss: 0.746002  [748864/984410]
loss: 0.854185  [755264/984410]
loss: 0.759316  [761664/984410]
loss: 0.789742  [768064/984410]
loss: 0.573387  [774464/984410]
loss: 0.586722  [780864/984410]
loss: 0.676882  [787264/984410]
loss: 0.786685  [793664/984410]
loss: 0.632604  [800064/984410]
loss: 0.710367  [806464/984410]
loss: 0.733512  [812864/984410]
loss: 0.863363  [819264/984410]
loss: 0.505661  [825664/984410]
loss: 0.552147  [832064/984410]
loss: 0.677344  [838464/984410]
loss: 0.663343  [844864/984410]
loss: 0.573939  [851264/984410]
loss: 0.969068  [857664/984410]
loss: 0.540668  [864064/984410]
loss: 0.956193  [870464/984410]
loss: 0.715198  [876864/984410]
loss: 0.581754  [883264/984410]
loss: 0.736832  [889664/984410]
loss: 0.627786  [896064/984410]
loss: 0.744398  [902464/984410]
loss: 0.668523  [908864/984410]
loss: 0.821121  [915264/984410]
loss: 0.592267  [921664/984410]
loss: 0.523762  [928064/984410]
loss: 0.709508  [934464/984410]
loss: 0.951191  [940864/984410]
loss: 0.526077  [947264/984410]
loss: 0.847458  [953664/984410]
loss: 0.801736  [960064/984410]
loss: 0.616974  [966464/984410]
loss: 0.622090  [972864/984410]
loss: 0.784703  [979264/984410]
Epoch 1/3, Training Loss (epoch average): 0.8108, Test Loss: 0.8747, Test Accuracy: 70.51%
loss: 0.750329  [   64/984410]
loss: 0.459416  [ 6464/984410]
loss: 0.690512  [12864/984410]
loss: 0.817875  [19264/984410]
loss: 0.414522  [25664/984410]
loss: 0.760175  [32064/984410]
loss: 0.669751  [38464/984410]
loss: 0.605343  [44864/984410]
loss: 0.728768  [51264/984410]
loss: 0.624847  [57664/984410]
loss: 0.696613  [64064/984410]
loss: 0.462640  [70464/984410]
loss: 0.672933  [76864/984410]
loss: 0.545504  [83264/984410]
loss: 0.469877  [89664/984410]
loss: 0.521012  [96064/984410]
loss: 0.565541  [102464/984410]
loss: 0.670437  [108864/984410]
loss: 0.625991  [115264/984410]
loss: 0.663074  [121664/984410]
loss: 0.730133  [128064/984410]
loss: 0.508066  [134464/984410]
loss: 0.638089  [140864/984410]
loss: 0.619418  [147264/984410]
loss: 0.764961  [153664/984410]
loss: 0.837222  [160064/984410]
loss: 0.765951  [166464/984410]
loss: 0.505155  [172864/984410]
loss: 0.272407  [179264/984410]
loss: 0.362781  [185664/984410]
loss: 0.536932  [192064/984410]
loss: 0.595957  [198464/984410]
loss: 0.565754  [204864/984410]
loss: 0.644058  [211264/984410]
loss: 0.560534  [217664/984410]
loss: 0.735338  [224064/984410]
loss: 0.528822  [230464/984410]
loss: 0.672108  [236864/984410]
loss: 0.535143  [243264/984410]
loss: 0.872524  [249664/984410]
loss: 0.760670  [256064/984410]
loss: 0.643591  [262464/984410]
loss: 0.757349  [268864/984410]
loss: 0.646969  [275264/984410]
loss: 0.670341  [281664/984410]
loss: 0.716998  [288064/984410]
loss: 0.432382  [294464/984410]
loss: 0.488395  [300864/984410]
loss: 0.495212  [307264/984410]
loss: 0.763764  [313664/984410]
loss: 0.513771  [320064/984410]
loss: 0.527069  [326464/984410]
loss: 0.776553  [332864/984410]
loss: 0.412811  [339264/984410]
loss: 0.641945  [345664/984410]
loss: 0.735573  [352064/984410]
loss: 0.726094  [358464/984410]
loss: 0.741137  [364864/984410]
loss: 0.629397  [371264/984410]
loss: 0.583620  [377664/984410]
loss: 0.464257  [384064/984410]
loss: 0.498288  [390464/984410]
loss: 0.854820  [396864/984410]
loss: 0.569481  [403264/984410]
loss: 0.756519  [409664/984410]
loss: 0.547945  [416064/984410]
loss: 0.823737  [422464/984410]
loss: 0.689398  [428864/984410]
loss: 0.448413  [435264/984410]
loss: 0.552107  [441664/984410]
loss: 0.423519  [448064/984410]
loss: 0.839815  [454464/984410]
loss: 0.681868  [460864/984410]
loss: 0.806245  [467264/984410]
loss: 0.765209  [473664/984410]
loss: 0.442454  [480064/984410]
loss: 0.835773  [486464/984410]
loss: 0.600436  [492864/984410]
loss: 0.602887  [499264/984410]
loss: 0.567086  [505664/984410]
loss: 0.814901  [512064/984410]
loss: 0.855203  [518464/984410]
loss: 0.699160  [524864/984410]
loss: 0.494572  [531264/984410]
loss: 1.103960  [537664/984410]
loss: 0.721643  [544064/984410]
loss: 0.660115  [550464/984410]
loss: 0.553911  [556864/984410]
loss: 0.500763  [563264/984410]
loss: 0.343695  [569664/984410]
loss: 0.510592  [576064/984410]
loss: 0.486114  [582464/984410]
loss: 0.592740  [588864/984410]
loss: 0.521829  [595264/984410]
loss: 0.764342  [601664/984410]
loss: 0.606620  [608064/984410]
loss: 0.614791  [614464/984410]
loss: 0.660226  [620864/984410]
loss: 0.599381  [627264/984410]
loss: 0.681058  [633664/984410]
loss: 0.597740  [640064/984410]
loss: 0.798605  [646464/984410]
loss: 0.646168  [652864/984410]
loss: 0.670467  [659264/984410]
loss: 0.529675  [665664/984410]
loss: 0.708406  [672064/984410]
loss: 0.698921  [678464/984410]
loss: 0.599719  [684864/984410]
loss: 0.671032  [691264/984410]
loss: 0.985534  [697664/984410]
loss: 0.689315  [704064/984410]
loss: 0.709194  [710464/984410]
loss: 0.360328  [716864/984410]
loss: 0.714586  [723264/984410]
loss: 0.698493  [729664/984410]
loss: 0.711072  [736064/984410]
loss: 0.587435  [742464/984410]
loss: 0.561184  [748864/984410]
loss: 0.592147  [755264/984410]
loss: 0.815904  [761664/984410]
loss: 0.680124  [768064/984410]
loss: 0.507606  [774464/984410]
loss: 0.689074  [780864/984410]
loss: 0.660959  [787264/984410]
loss: 0.634107  [793664/984410]
loss: 0.756598  [800064/984410]
loss: 0.534629  [806464/984410]
loss: 0.524326  [812864/984410]
loss: 0.765191  [819264/984410]
loss: 0.708114  [825664/984410]
loss: 0.964131  [832064/984410]
loss: 0.836785  [838464/984410]
loss: 0.669358  [844864/984410]
loss: 0.645895  [851264/984410]
loss: 0.605987  [857664/984410]
loss: 0.764488  [864064/984410]
loss: 0.924271  [870464/984410]
loss: 0.850784  [876864/984410]
loss: 0.790850  [883264/984410]
loss: 0.564181  [889664/984410]
loss: 0.566885  [896064/984410]
loss: 0.505809  [902464/984410]
loss: 0.595785  [908864/984410]
loss: 0.701442  [915264/984410]
loss: 0.898132  [921664/984410]
loss: 0.803097  [928064/984410]
loss: 0.679343  [934464/984410]
loss: 0.496961  [940864/984410]
loss: 0.641045  [947264/984410]
loss: 0.686438  [953664/984410]
loss: 0.534438  [960064/984410]
loss: 0.541665  [966464/984410]
loss: 0.730911  [972864/984410]
loss: 0.685889  [979264/984410]
Epoch 2/3, Training Loss (epoch average): 0.6365, Test Loss: 0.7628, Test Accuracy: 74.25%
loss: 0.564162  [   64/984410]
loss: 0.473838  [ 6464/984410]
loss: 0.567351  [12864/984410]
loss: 0.438164  [19264/984410]
loss: 0.412125  [25664/984410]
loss: 0.534367  [32064/984410]
loss: 0.538491  [38464/984410]
loss: 0.393559  [44864/984410]
loss: 0.679037  [51264/984410]
loss: 0.582527  [57664/984410]
loss: 0.677475  [64064/984410]
loss: 0.330568  [70464/984410]
loss: 0.652171  [76864/984410]
loss: 0.622907  [83264/984410]
loss: 0.350904  [89664/984410]
loss: 0.777349  [96064/984410]
loss: 0.579998  [102464/984410]
loss: 0.539158  [108864/984410]
loss: 0.438319  [115264/984410]
loss: 0.603046  [121664/984410]
loss: 0.430338  [128064/984410]
loss: 0.567852  [134464/984410]
loss: 0.476714  [140864/984410]
loss: 0.543223  [147264/984410]
loss: 0.655612  [153664/984410]
loss: 0.512444  [160064/984410]
loss: 0.448511  [166464/984410]
loss: 0.628279  [172864/984410]
loss: 0.721683  [179264/984410]
loss: 0.507546  [185664/984410]
loss: 0.679598  [192064/984410]
loss: 0.583284  [198464/984410]
loss: 0.686123  [204864/984410]
loss: 0.536772  [211264/984410]
loss: 0.636159  [217664/984410]
loss: 0.477605  [224064/984410]
loss: 0.503786  [230464/984410]
loss: 0.570183  [236864/984410]
loss: 0.600254  [243264/984410]
loss: 0.440224  [249664/984410]
loss: 0.476155  [256064/984410]
loss: 0.452963  [262464/984410]
loss: 0.494437  [268864/984410]
loss: 0.564544  [275264/984410]
loss: 0.407997  [281664/984410]
loss: 0.445705  [288064/984410]
loss: 0.701906  [294464/984410]
loss: 0.683879  [300864/984410]
loss: 0.601332  [307264/984410]
loss: 0.718979  [313664/984410]
loss: 0.423175  [320064/984410]
loss: 0.560103  [326464/984410]
loss: 0.490571  [332864/984410]
loss: 0.685335  [339264/984410]
loss: 0.446784  [345664/984410]
loss: 0.466962  [352064/984410]
loss: 0.512872  [358464/984410]
loss: 0.629154  [364864/984410]
loss: 0.398477  [371264/984410]
loss: 0.373876  [377664/984410]
loss: 0.386554  [384064/984410]
loss: 0.626811  [390464/984410]
loss: 0.658831  [396864/984410]
loss: 0.700374  [403264/984410]
loss: 0.545101  [409664/984410]
loss: 0.649030  [416064/984410]
loss: 0.596760  [422464/984410]
loss: 0.559636  [428864/984410]
loss: 0.624709  [435264/984410]
loss: 0.488964  [441664/984410]
loss: 0.702925  [448064/984410]
loss: 0.492236  [454464/984410]
loss: 0.791903  [460864/984410]
loss: 0.464907  [467264/984410]
loss: 0.637283  [473664/984410]
loss: 0.402748  [480064/984410]
loss: 0.697571  [486464/984410]
loss: 0.406185  [492864/984410]
loss: 0.559602  [499264/984410]
loss: 0.568321  [505664/984410]
loss: 0.625214  [512064/984410]
loss: 0.481864  [518464/984410]
loss: 0.435065  [524864/984410]
loss: 0.545798  [531264/984410]
loss: 0.393776  [537664/984410]
loss: 0.466881  [544064/984410]
loss: 0.441124  [550464/984410]
loss: 0.755380  [556864/984410]
loss: 0.702038  [563264/984410]
loss: 0.584646  [569664/984410]
loss: 0.549936  [576064/984410]
loss: 0.453367  [582464/984410]
loss: 0.684791  [588864/984410]
loss: 0.619843  [595264/984410]
loss: 0.552684  [601664/984410]
loss: 0.438503  [608064/984410]
loss: 0.757861  [614464/984410]
loss: 0.616076  [620864/984410]
loss: 0.504221  [627264/984410]
loss: 0.759500  [633664/984410]
loss: 0.559302  [640064/984410]
loss: 0.543200  [646464/984410]
loss: 0.576351  [652864/984410]
loss: 0.580654  [659264/984410]
loss: 0.793618  [665664/984410]
loss: 0.623664  [672064/984410]
loss: 0.590309  [678464/984410]
loss: 0.592503  [684864/984410]
loss: 0.627013  [691264/984410]
loss: 0.478316  [697664/984410]
loss: 0.707016  [704064/984410]
loss: 0.422981  [710464/984410]
loss: 0.400965  [716864/984410]
loss: 0.588886  [723264/984410]
loss: 0.550352  [729664/984410]
loss: 0.581487  [736064/984410]
loss: 0.531056  [742464/984410]
loss: 0.400326  [748864/984410]
loss: 0.525151  [755264/984410]
loss: 0.471497  [761664/984410]
loss: 0.714582  [768064/984410]
loss: 0.789355  [774464/984410]
loss: 0.620136  [780864/984410]
loss: 0.418053  [787264/984410]
loss: 0.459024  [793664/984410]
loss: 0.397592  [800064/984410]
loss: 0.733647  [806464/984410]
loss: 0.681528  [812864/984410]
loss: 0.521185  [819264/984410]
loss: 0.571230  [825664/984410]
loss: 0.636180  [832064/984410]
loss: 0.528693  [838464/984410]
loss: 0.614276  [844864/984410]
loss: 0.683156  [851264/984410]
loss: 0.507060  [857664/984410]
loss: 0.674663  [864064/984410]
loss: 0.623751  [870464/984410]
loss: 0.553845  [876864/984410]
loss: 0.701744  [883264/984410]
loss: 0.406019  [889664/984410]
loss: 0.475947  [896064/984410]
loss: 0.749867  [902464/984410]
loss: 0.631709  [908864/984410]
loss: 0.402579  [915264/984410]
loss: 0.450285  [921664/984410]
loss: 0.556002  [928064/984410]
loss: 0.708478  [934464/984410]
loss: 0.508601  [940864/984410]
loss: 0.753815  [947264/984410]
loss: 0.510806  [953664/984410]
loss: 0.534946  [960064/984410]
loss: 0.596885  [966464/984410]
loss: 0.611261  [972864/984410]
loss: 0.523345  [979264/984410]
Epoch 3/3, Training Loss (epoch average): 0.5545, Test Loss: 0.8692, Test Accuracy: 71.12%
The loss curve has been saved as 'training_plots/loss_curve_20250328-170509.png'.
