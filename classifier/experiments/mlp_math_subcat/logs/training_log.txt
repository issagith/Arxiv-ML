loss: 3.414299  [  128/251077]
loss: 3.060438  [12928/251077]
loss: 2.889070  [25728/251077]
loss: 2.447891  [38528/251077]
loss: 2.448214  [51328/251077]
loss: 2.101884  [64128/251077]
loss: 2.057496  [76928/251077]
loss: 2.170445  [89728/251077]
loss: 1.715668  [102528/251077]
loss: 1.755905  [115328/251077]
loss: 1.630944  [128128/251077]
loss: 2.112663  [140928/251077]
loss: 1.638820  [153728/251077]
loss: 1.750499  [166528/251077]
loss: 1.455908  [179328/251077]
loss: 1.532634  [192128/251077]
loss: 1.537152  [204928/251077]
loss: 1.503509  [217728/251077]
loss: 1.406199  [230528/251077]
loss: 1.371575  [243328/251077]
Epoch 1/5, Training Loss (epoch avg): 1.9374, Test Loss: 1.3433, Test Accuracy: 59.94%
loss: 1.542074  [  128/251077]
loss: 1.446145  [12928/251077]
loss: 1.568797  [25728/251077]
loss: 1.289507  [38528/251077]
loss: 1.313688  [51328/251077]
loss: 1.229913  [64128/251077]
loss: 1.287741  [76928/251077]
loss: 1.532841  [89728/251077]
loss: 1.173837  [102528/251077]
loss: 1.316014  [115328/251077]
loss: 1.097033  [128128/251077]
loss: 1.675201  [140928/251077]
loss: 1.363408  [153728/251077]
loss: 1.339376  [166528/251077]
loss: 1.122167  [179328/251077]
loss: 1.095617  [192128/251077]
loss: 1.334494  [204928/251077]
loss: 1.207256  [217728/251077]
loss: 1.193813  [230528/251077]
loss: 1.125918  [243328/251077]
Epoch 2/5, Training Loss (epoch avg): 1.3151, Test Loss: 1.1578, Test Accuracy: 65.37%
loss: 1.231785  [  128/251077]
loss: 1.171684  [12928/251077]
loss: 1.353255  [25728/251077]
loss: 0.932499  [38528/251077]
loss: 1.171755  [51328/251077]
loss: 1.016813  [64128/251077]
loss: 1.186905  [76928/251077]
loss: 1.237426  [89728/251077]
loss: 1.042334  [102528/251077]
loss: 1.067771  [115328/251077]
loss: 0.898242  [128128/251077]
loss: 1.521608  [140928/251077]
loss: 1.097272  [153728/251077]
loss: 1.097381  [166528/251077]
loss: 1.047857  [179328/251077]
loss: 0.978062  [192128/251077]
loss: 1.216646  [204928/251077]
loss: 1.052248  [217728/251077]
loss: 1.022308  [230528/251077]
loss: 1.034948  [243328/251077]
Epoch 3/5, Training Loss (epoch avg): 1.1490, Test Loss: 1.0791, Test Accuracy: 67.63%
loss: 1.200461  [  128/251077]
loss: 1.054357  [12928/251077]
loss: 1.288232  [25728/251077]
loss: 0.891376  [38528/251077]
loss: 1.070964  [51328/251077]
loss: 0.857416  [64128/251077]
loss: 1.043272  [76928/251077]
loss: 1.205051  [89728/251077]
loss: 0.904065  [102528/251077]
loss: 1.024396  [115328/251077]
loss: 0.929686  [128128/251077]
loss: 1.454044  [140928/251077]
loss: 1.064844  [153728/251077]
loss: 0.941205  [166528/251077]
loss: 0.970887  [179328/251077]
loss: 0.894605  [192128/251077]
loss: 1.134138  [204928/251077]
loss: 1.026363  [217728/251077]
loss: 0.986713  [230528/251077]
loss: 0.913836  [243328/251077]
Epoch 4/5, Training Loss (epoch avg): 1.0530, Test Loss: 1.0385, Test Accuracy: 68.76%
loss: 1.048544  [  128/251077]
loss: 0.920867  [12928/251077]
loss: 1.255358  [25728/251077]
loss: 0.796690  [38528/251077]
loss: 0.941749  [51328/251077]
loss: 0.867996  [64128/251077]
loss: 1.029164  [76928/251077]
loss: 1.169591  [89728/251077]
loss: 0.891972  [102528/251077]
loss: 0.906086  [115328/251077]
loss: 0.760022  [128128/251077]
loss: 1.275775  [140928/251077]
loss: 0.907387  [153728/251077]
loss: 0.930057  [166528/251077]
loss: 0.867267  [179328/251077]
loss: 0.842305  [192128/251077]
loss: 1.103036  [204928/251077]
loss: 0.845189  [217728/251077]
loss: 0.889332  [230528/251077]
loss: 0.801492  [243328/251077]
Epoch 5/5, Training Loss (epoch avg): 0.9839, Test Loss: 1.0137, Test Accuracy: 69.36%
