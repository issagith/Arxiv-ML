loss: 3.024025  [   64/986091]
loss: 2.206452  [ 6464/986091]
loss: 1.637421  [12864/986091]
loss: 1.558561  [19264/986091]
loss: 1.664269  [25664/986091]
loss: 1.409698  [32064/986091]
loss: 1.469699  [38464/986091]
loss: 1.347495  [44864/986091]
loss: 1.524196  [51264/986091]
loss: 1.319448  [57664/986091]
loss: 1.312109  [64064/986091]
loss: 1.318221  [70464/986091]
loss: 1.207959  [76864/986091]
loss: 1.133786  [83264/986091]
loss: 1.116768  [89664/986091]
loss: 0.917027  [96064/986091]
loss: 1.078537  [102464/986091]
loss: 1.251775  [108864/986091]
loss: 1.087523  [115264/986091]
loss: 1.146536  [121664/986091]
loss: 0.929861  [128064/986091]
loss: 1.144177  [134464/986091]
loss: 1.223355  [140864/986091]
loss: 1.091257  [147264/986091]
loss: 1.050377  [153664/986091]
loss: 1.001656  [160064/986091]
loss: 1.007813  [166464/986091]
loss: 0.861139  [172864/986091]
loss: 1.180234  [179264/986091]
loss: 1.079043  [185664/986091]
loss: 0.802696  [192064/986091]
loss: 1.015771  [198464/986091]
loss: 1.206640  [204864/986091]
loss: 0.844289  [211264/986091]
loss: 0.877253  [217664/986091]
loss: 0.943017  [224064/986091]
loss: 0.994739  [230464/986091]
loss: 0.926092  [236864/986091]
loss: 0.781414  [243264/986091]
loss: 0.777199  [249664/986091]
loss: 0.854208  [256064/986091]
loss: 0.636708  [262464/986091]
loss: 0.842270  [268864/986091]
loss: 0.728551  [275264/986091]
loss: 0.470384  [281664/986091]
loss: 0.650251  [288064/986091]
loss: 0.746674  [294464/986091]
loss: 0.637903  [300864/986091]
loss: 0.946997  [307264/986091]
loss: 1.013988  [313664/986091]
loss: 0.773325  [320064/986091]
loss: 0.719233  [326464/986091]
loss: 0.844237  [332864/986091]
loss: 0.668704  [339264/986091]
loss: 0.824172  [345664/986091]
loss: 0.590261  [352064/986091]
loss: 0.516204  [358464/986091]
loss: 1.013668  [364864/986091]
loss: 0.610484  [371264/986091]
loss: 0.634358  [377664/986091]
loss: 0.636393  [384064/986091]
loss: 0.698691  [390464/986091]
loss: 0.718072  [396864/986091]
loss: 0.680746  [403264/986091]
loss: 0.580870  [409664/986091]
loss: 0.716407  [416064/986091]
loss: 0.653433  [422464/986091]
loss: 0.493240  [428864/986091]
loss: 0.509889  [435264/986091]
loss: 0.678174  [441664/986091]
loss: 0.602361  [448064/986091]
loss: 0.630695  [454464/986091]
loss: 0.655147  [460864/986091]
loss: 0.586837  [467264/986091]
loss: 0.624647  [473664/986091]
loss: 0.545138  [480064/986091]
loss: 0.638493  [486464/986091]
loss: 0.623237  [492864/986091]
loss: 0.993003  [499264/986091]
loss: 0.558289  [505664/986091]
loss: 0.748818  [512064/986091]
loss: 0.779400  [518464/986091]
loss: 0.755307  [524864/986091]
loss: 0.646439  [531264/986091]
loss: 0.459677  [537664/986091]
loss: 0.526522  [544064/986091]
loss: 0.412286  [550464/986091]
loss: 0.865511  [556864/986091]
loss: 0.658153  [563264/986091]
loss: 0.526318  [569664/986091]
loss: 0.690656  [576064/986091]
loss: 0.538277  [582464/986091]
loss: 0.806328  [588864/986091]
loss: 0.510963  [595264/986091]
loss: 0.524234  [601664/986091]
loss: 0.858247  [608064/986091]
loss: 0.579624  [614464/986091]
loss: 0.677175  [620864/986091]
loss: 0.561994  [627264/986091]
loss: 0.865982  [633664/986091]
loss: 0.548456  [640064/986091]
loss: 0.345356  [646464/986091]
loss: 0.878232  [652864/986091]
loss: 0.674935  [659264/986091]
loss: 0.760869  [665664/986091]
loss: 0.470286  [672064/986091]
loss: 0.539235  [678464/986091]
loss: 0.586507  [684864/986091]
loss: 0.838413  [691264/986091]
loss: 0.625307  [697664/986091]
loss: 0.553969  [704064/986091]
loss: 0.796758  [710464/986091]
loss: 0.732161  [716864/986091]
loss: 0.349476  [723264/986091]
loss: 0.793458  [729664/986091]
loss: 0.567015  [736064/986091]
loss: 0.569493  [742464/986091]
loss: 0.503888  [748864/986091]
loss: 0.573079  [755264/986091]
loss: 0.706801  [761664/986091]
loss: 0.755255  [768064/986091]
loss: 0.491338  [774464/986091]
loss: 0.713062  [780864/986091]
loss: 0.280682  [787264/986091]
loss: 0.706085  [793664/986091]
loss: 0.480139  [800064/986091]
loss: 0.377838  [806464/986091]
loss: 0.754982  [812864/986091]
loss: 0.537755  [819264/986091]
loss: 0.384108  [825664/986091]
loss: 0.435293  [832064/986091]
loss: 0.677808  [838464/986091]
loss: 0.488592  [844864/986091]
loss: 0.483145  [851264/986091]
loss: 0.291505  [857664/986091]
loss: 0.820096  [864064/986091]
loss: 0.530425  [870464/986091]
loss: 0.407267  [876864/986091]
loss: 0.686718  [883264/986091]
loss: 0.590267  [889664/986091]
loss: 0.454610  [896064/986091]
loss: 0.644587  [902464/986091]
loss: 0.517245  [908864/986091]
loss: 0.544404  [915264/986091]
loss: 0.445088  [921664/986091]
loss: 0.769386  [928064/986091]
loss: 0.670253  [934464/986091]
loss: 0.601115  [940864/986091]
loss: 0.504245  [947264/986091]
loss: 0.649270  [953664/986091]
loss: 0.353456  [960064/986091]
loss: 0.629047  [966464/986091]
loss: 0.429469  [972864/986091]
loss: 0.690728  [979264/986091]
loss: 0.378802  [985664/986091]
Epoch 1/5, Training Loss (epoch avg): 0.7826, Test Loss: 0.5518, Test Accuracy: 80.69%
loss: 0.477510  [   64/986091]
loss: 0.786475  [ 6464/986091]
loss: 0.477520  [12864/986091]
loss: 0.594122  [19264/986091]
loss: 0.734520  [25664/986091]
loss: 0.588854  [32064/986091]
loss: 0.515526  [38464/986091]
loss: 0.594889  [44864/986091]
loss: 0.573046  [51264/986091]
loss: 0.571869  [57664/986091]
loss: 0.467107  [64064/986091]
loss: 0.736717  [70464/986091]
loss: 0.726441  [76864/986091]
loss: 0.594833  [83264/986091]
loss: 0.612185  [89664/986091]
loss: 0.441791  [96064/986091]
loss: 0.547715  [102464/986091]
loss: 0.471423  [108864/986091]
loss: 0.899112  [115264/986091]
loss: 0.580048  [121664/986091]
loss: 0.435346  [128064/986091]
loss: 0.670048  [134464/986091]
loss: 0.788505  [140864/986091]
loss: 0.521147  [147264/986091]
loss: 0.382457  [153664/986091]
loss: 0.535138  [160064/986091]
loss: 0.567306  [166464/986091]
loss: 0.503499  [172864/986091]
loss: 0.613792  [179264/986091]
loss: 0.719864  [185664/986091]
loss: 0.435132  [192064/986091]
loss: 0.528601  [198464/986091]
loss: 0.451329  [204864/986091]
loss: 0.549567  [211264/986091]
loss: 0.671299  [217664/986091]
loss: 0.546444  [224064/986091]
loss: 0.838817  [230464/986091]
loss: 0.564721  [236864/986091]
loss: 0.487483  [243264/986091]
loss: 0.383553  [249664/986091]
loss: 0.475943  [256064/986091]
loss: 0.317115  [262464/986091]
loss: 0.630524  [268864/986091]
loss: 0.454457  [275264/986091]
loss: 0.318360  [281664/986091]
loss: 0.391907  [288064/986091]
loss: 0.454093  [294464/986091]
loss: 0.351061  [300864/986091]
loss: 0.767722  [307264/986091]
loss: 0.639349  [313664/986091]
loss: 0.499561  [320064/986091]
loss: 0.504780  [326464/986091]
loss: 0.558987  [332864/986091]
loss: 0.523844  [339264/986091]
loss: 0.505436  [345664/986091]
loss: 0.358888  [352064/986091]
loss: 0.270965  [358464/986091]
loss: 0.711134  [364864/986091]
loss: 0.528643  [371264/986091]
loss: 0.434055  [377664/986091]
loss: 0.484725  [384064/986091]
loss: 0.561295  [390464/986091]
loss: 0.693363  [396864/986091]
loss: 0.628074  [403264/986091]
loss: 0.499922  [409664/986091]
loss: 0.495075  [416064/986091]
loss: 0.587362  [422464/986091]
loss: 0.452609  [428864/986091]
loss: 0.328348  [435264/986091]
loss: 0.529820  [441664/986091]
loss: 0.433033  [448064/986091]
loss: 0.434828  [454464/986091]
loss: 0.458704  [460864/986091]
loss: 0.453141  [467264/986091]
loss: 0.461086  [473664/986091]
loss: 0.387528  [480064/986091]
loss: 0.481269  [486464/986091]
loss: 0.549049  [492864/986091]
loss: 0.641689  [499264/986091]
loss: 0.439984  [505664/986091]
loss: 0.647654  [512064/986091]
loss: 0.725682  [518464/986091]
loss: 0.582440  [524864/986091]
loss: 0.522132  [531264/986091]
loss: 0.415231  [537664/986091]
loss: 0.409668  [544064/986091]
loss: 0.389141  [550464/986091]
loss: 0.702566  [556864/986091]
loss: 0.544563  [563264/986091]
loss: 0.377922  [569664/986091]
loss: 0.511336  [576064/986091]
loss: 0.393878  [582464/986091]
loss: 0.651467  [588864/986091]
loss: 0.370140  [595264/986091]
loss: 0.482804  [601664/986091]
loss: 0.730985  [608064/986091]
loss: 0.489093  [614464/986091]
loss: 0.555777  [620864/986091]
loss: 0.406394  [627264/986091]
loss: 0.680605  [633664/986091]
loss: 0.411683  [640064/986091]
loss: 0.289728  [646464/986091]
loss: 0.696935  [652864/986091]
loss: 0.627068  [659264/986091]
loss: 0.557199  [665664/986091]
loss: 0.365618  [672064/986091]
loss: 0.525668  [678464/986091]
loss: 0.477040  [684864/986091]
loss: 0.824969  [691264/986091]
loss: 0.519666  [697664/986091]
loss: 0.472372  [704064/986091]
loss: 0.797430  [710464/986091]
loss: 0.620225  [716864/986091]
loss: 0.297914  [723264/986091]
loss: 0.634997  [729664/986091]
loss: 0.510449  [736064/986091]
loss: 0.592105  [742464/986091]
loss: 0.423365  [748864/986091]
loss: 0.521393  [755264/986091]
loss: 0.574324  [761664/986091]
loss: 0.582024  [768064/986091]
loss: 0.412667  [774464/986091]
loss: 0.718856  [780864/986091]
loss: 0.255446  [787264/986091]
loss: 0.564661  [793664/986091]
loss: 0.427587  [800064/986091]
loss: 0.373466  [806464/986091]
loss: 0.621252  [812864/986091]
loss: 0.386953  [819264/986091]
loss: 0.362418  [825664/986091]
loss: 0.405408  [832064/986091]
loss: 0.586848  [838464/986091]
loss: 0.413827  [844864/986091]
loss: 0.348193  [851264/986091]
loss: 0.252651  [857664/986091]
loss: 0.666138  [864064/986091]
loss: 0.467985  [870464/986091]
loss: 0.330008  [876864/986091]
loss: 0.545142  [883264/986091]
loss: 0.476884  [889664/986091]
loss: 0.360142  [896064/986091]
loss: 0.501025  [902464/986091]
loss: 0.480204  [908864/986091]
loss: 0.434308  [915264/986091]
loss: 0.403596  [921664/986091]
loss: 0.600950  [928064/986091]
loss: 0.609049  [934464/986091]
loss: 0.422200  [940864/986091]
loss: 0.387206  [947264/986091]
loss: 0.556951  [953664/986091]
loss: 0.240253  [960064/986091]
loss: 0.502922  [966464/986091]
loss: 0.377933  [972864/986091]
loss: 0.595375  [979264/986091]
loss: 0.336686  [985664/986091]
Epoch 2/5, Training Loss (epoch avg): 0.5329, Test Loss: 0.5132, Test Accuracy: 81.90%
loss: 0.491522  [   64/986091]
loss: 0.601491  [ 6464/986091]
loss: 0.443851  [12864/986091]
loss: 0.593190  [19264/986091]
loss: 0.577521  [25664/986091]
loss: 0.452591  [32064/986091]
loss: 0.468593  [38464/986091]
loss: 0.563094  [44864/986091]
loss: 0.585759  [51264/986091]
loss: 0.502988  [57664/986091]
loss: 0.427419  [64064/986091]
loss: 0.702148  [70464/986091]
loss: 0.636873  [76864/986091]
loss: 0.488088  [83264/986091]
loss: 0.563325  [89664/986091]
loss: 0.388814  [96064/986091]
loss: 0.472407  [102464/986091]
loss: 0.466045  [108864/986091]
loss: 0.842233  [115264/986091]
loss: 0.441107  [121664/986091]
loss: 0.384643  [128064/986091]
loss: 0.499382  [134464/986091]
loss: 0.603560  [140864/986091]
loss: 0.495144  [147264/986091]
loss: 0.300965  [153664/986091]
loss: 0.412470  [160064/986091]
loss: 0.460578  [166464/986091]
loss: 0.525008  [172864/986091]
loss: 0.579217  [179264/986091]
loss: 0.673062  [185664/986091]
loss: 0.409774  [192064/986091]
loss: 0.606286  [198464/986091]
loss: 0.482927  [204864/986091]
loss: 0.440996  [211264/986091]
loss: 0.513688  [217664/986091]
loss: 0.569288  [224064/986091]
loss: 0.770040  [230464/986091]
loss: 0.615917  [236864/986091]
loss: 0.446095  [243264/986091]
loss: 0.376162  [249664/986091]
loss: 0.399180  [256064/986091]
loss: 0.285605  [262464/986091]
loss: 0.575416  [268864/986091]
loss: 0.363748  [275264/986091]
loss: 0.272601  [281664/986091]
loss: 0.292736  [288064/986091]
loss: 0.444470  [294464/986091]
loss: 0.311210  [300864/986091]
loss: 0.617717  [307264/986091]
loss: 0.615241  [313664/986091]
loss: 0.489195  [320064/986091]
loss: 0.492205  [326464/986091]
loss: 0.544201  [332864/986091]
loss: 0.340149  [339264/986091]
loss: 0.457847  [345664/986091]
loss: 0.299647  [352064/986091]
loss: 0.213234  [358464/986091]
loss: 0.611222  [364864/986091]
loss: 0.459611  [371264/986091]
loss: 0.354442  [377664/986091]
loss: 0.427376  [384064/986091]
loss: 0.524981  [390464/986091]
loss: 0.650107  [396864/986091]
loss: 0.490986  [403264/986091]
loss: 0.418907  [409664/986091]
loss: 0.421111  [416064/986091]
loss: 0.619488  [422464/986091]
loss: 0.361032  [428864/986091]
loss: 0.298621  [435264/986091]
loss: 0.556972  [441664/986091]
loss: 0.420654  [448064/986091]
loss: 0.426120  [454464/986091]
loss: 0.478513  [460864/986091]
loss: 0.465947  [467264/986091]
loss: 0.490619  [473664/986091]
loss: 0.297093  [480064/986091]
loss: 0.368057  [486464/986091]
loss: 0.513212  [492864/986091]
loss: 0.711497  [499264/986091]
loss: 0.447369  [505664/986091]
loss: 0.635905  [512064/986091]
loss: 0.706474  [518464/986091]
loss: 0.549406  [524864/986091]
loss: 0.534360  [531264/986091]
loss: 0.442314  [537664/986091]
loss: 0.358596  [544064/986091]
loss: 0.353465  [550464/986091]
loss: 0.660196  [556864/986091]
loss: 0.452974  [563264/986091]
loss: 0.374185  [569664/986091]
loss: 0.501823  [576064/986091]
loss: 0.420756  [582464/986091]
loss: 0.499766  [588864/986091]
loss: 0.440412  [595264/986091]
loss: 0.411048  [601664/986091]
loss: 0.648171  [608064/986091]
loss: 0.444414  [614464/986091]
loss: 0.411615  [620864/986091]
loss: 0.363034  [627264/986091]
loss: 0.669498  [633664/986091]
loss: 0.373533  [640064/986091]
loss: 0.286855  [646464/986091]
loss: 0.668533  [652864/986091]
loss: 0.562047  [659264/986091]
loss: 0.516276  [665664/986091]
loss: 0.379257  [672064/986091]
loss: 0.485523  [678464/986091]
loss: 0.444287  [684864/986091]
loss: 0.664057  [691264/986091]
loss: 0.529425  [697664/986091]
loss: 0.426543  [704064/986091]
loss: 0.783819  [710464/986091]
loss: 0.503716  [716864/986091]
loss: 0.276048  [723264/986091]
loss: 0.600288  [729664/986091]
loss: 0.463858  [736064/986091]
loss: 0.564540  [742464/986091]
loss: 0.386596  [748864/986091]
loss: 0.402083  [755264/986091]
loss: 0.511249  [761664/986091]
loss: 0.498007  [768064/986091]
loss: 0.414445  [774464/986091]
loss: 0.682723  [780864/986091]
loss: 0.212129  [787264/986091]
loss: 0.395966  [793664/986091]
loss: 0.431850  [800064/986091]
loss: 0.332228  [806464/986091]
loss: 0.492616  [812864/986091]
loss: 0.418156  [819264/986091]
loss: 0.297786  [825664/986091]
loss: 0.507891  [832064/986091]
loss: 0.483603  [838464/986091]
loss: 0.358918  [844864/986091]
loss: 0.386575  [851264/986091]
loss: 0.204722  [857664/986091]
loss: 0.673842  [864064/986091]
loss: 0.411774  [870464/986091]
loss: 0.325812  [876864/986091]
loss: 0.589121  [883264/986091]
loss: 0.416581  [889664/986091]
loss: 0.365975  [896064/986091]
loss: 0.443494  [902464/986091]
loss: 0.375871  [908864/986091]
loss: 0.433813  [915264/986091]
loss: 0.429926  [921664/986091]
loss: 0.480932  [928064/986091]
loss: 0.605535  [934464/986091]
loss: 0.486193  [940864/986091]
loss: 0.407669  [947264/986091]
loss: 0.610346  [953664/986091]
loss: 0.205981  [960064/986091]
loss: 0.383005  [966464/986091]
loss: 0.328239  [972864/986091]
loss: 0.583134  [979264/986091]
loss: 0.279191  [985664/986091]
Epoch 3/5, Training Loss (epoch avg): 0.4805, Test Loss: 0.5042, Test Accuracy: 82.19%
loss: 0.460264  [   64/986091]
loss: 0.631320  [ 6464/986091]
loss: 0.423789  [12864/986091]
loss: 0.494392  [19264/986091]
loss: 0.546634  [25664/986091]
loss: 0.477488  [32064/986091]
loss: 0.367080  [38464/986091]
loss: 0.511279  [44864/986091]
loss: 0.569728  [51264/986091]
loss: 0.491710  [57664/986091]
loss: 0.404065  [64064/986091]
loss: 0.607030  [70464/986091]
loss: 0.592308  [76864/986091]
loss: 0.482101  [83264/986091]
loss: 0.533726  [89664/986091]
loss: 0.385656  [96064/986091]
loss: 0.471942  [102464/986091]
loss: 0.462739  [108864/986091]
loss: 0.703799  [115264/986091]
loss: 0.472889  [121664/986091]
loss: 0.406823  [128064/986091]
loss: 0.517116  [134464/986091]
loss: 0.534588  [140864/986091]
loss: 0.435035  [147264/986091]
loss: 0.273831  [153664/986091]
loss: 0.374931  [160064/986091]
loss: 0.436865  [166464/986091]
loss: 0.466118  [172864/986091]
loss: 0.584941  [179264/986091]
loss: 0.618807  [185664/986091]
loss: 0.423291  [192064/986091]
loss: 0.470946  [198464/986091]
loss: 0.378729  [204864/986091]
loss: 0.458547  [211264/986091]
loss: 0.539948  [217664/986091]
loss: 0.475447  [224064/986091]
loss: 0.725866  [230464/986091]
loss: 0.587730  [236864/986091]
loss: 0.435780  [243264/986091]
loss: 0.359745  [249664/986091]
loss: 0.375132  [256064/986091]
loss: 0.253719  [262464/986091]
loss: 0.544619  [268864/986091]
loss: 0.347106  [275264/986091]
loss: 0.228328  [281664/986091]
loss: 0.321330  [288064/986091]
loss: 0.382071  [294464/986091]
loss: 0.289902  [300864/986091]
loss: 0.470289  [307264/986091]
loss: 0.687026  [313664/986091]
loss: 0.455233  [320064/986091]
loss: 0.449207  [326464/986091]
loss: 0.612648  [332864/986091]
loss: 0.403793  [339264/986091]
loss: 0.408417  [345664/986091]
loss: 0.309994  [352064/986091]
loss: 0.205655  [358464/986091]
loss: 0.532324  [364864/986091]
loss: 0.399926  [371264/986091]
loss: 0.287591  [377664/986091]
loss: 0.403973  [384064/986091]
loss: 0.508130  [390464/986091]
loss: 0.590695  [396864/986091]
loss: 0.488573  [403264/986091]
loss: 0.386680  [409664/986091]
loss: 0.421545  [416064/986091]
loss: 0.534000  [422464/986091]
loss: 0.373016  [428864/986091]
loss: 0.246451  [435264/986091]
loss: 0.545874  [441664/986091]
loss: 0.400797  [448064/986091]
loss: 0.456446  [454464/986091]
loss: 0.415992  [460864/986091]
loss: 0.341398  [467264/986091]
loss: 0.391662  [473664/986091]
loss: 0.228631  [480064/986091]
loss: 0.405366  [486464/986091]
loss: 0.569715  [492864/986091]
loss: 0.511214  [499264/986091]
loss: 0.459885  [505664/986091]
loss: 0.618840  [512064/986091]
loss: 0.615842  [518464/986091]
loss: 0.541837  [524864/986091]
loss: 0.480670  [531264/986091]
loss: 0.434618  [537664/986091]
loss: 0.330414  [544064/986091]
loss: 0.344040  [550464/986091]
loss: 0.592920  [556864/986091]
loss: 0.448331  [563264/986091]
loss: 0.375687  [569664/986091]
loss: 0.422625  [576064/986091]
loss: 0.406017  [582464/986091]
loss: 0.621280  [588864/986091]
loss: 0.357432  [595264/986091]
loss: 0.421537  [601664/986091]
loss: 0.627279  [608064/986091]
loss: 0.419769  [614464/986091]
loss: 0.407764  [620864/986091]
loss: 0.373163  [627264/986091]
loss: 0.661104  [633664/986091]
loss: 0.333319  [640064/986091]
loss: 0.254334  [646464/986091]
loss: 0.652306  [652864/986091]
loss: 0.548939  [659264/986091]
loss: 0.535108  [665664/986091]
loss: 0.303863  [672064/986091]
loss: 0.386066  [678464/986091]
loss: 0.341896  [684864/986091]
loss: 0.665507  [691264/986091]
loss: 0.441013  [697664/986091]
loss: 0.315698  [704064/986091]
loss: 0.748345  [710464/986091]
loss: 0.462935  [716864/986091]
loss: 0.244764  [723264/986091]
loss: 0.531690  [729664/986091]
loss: 0.440515  [736064/986091]
loss: 0.543358  [742464/986091]
loss: 0.363512  [748864/986091]
loss: 0.524460  [755264/986091]
loss: 0.535782  [761664/986091]
loss: 0.404383  [768064/986091]
loss: 0.379416  [774464/986091]
loss: 0.647958  [780864/986091]
loss: 0.191838  [787264/986091]
loss: 0.383182  [793664/986091]
loss: 0.352349  [800064/986091]
loss: 0.274848  [806464/986091]
loss: 0.498498  [812864/986091]
loss: 0.390760  [819264/986091]
loss: 0.391694  [825664/986091]
loss: 0.361784  [832064/986091]
loss: 0.437169  [838464/986091]
loss: 0.387768  [844864/986091]
loss: 0.333710  [851264/986091]
loss: 0.218534  [857664/986091]
loss: 0.682374  [864064/986091]
loss: 0.440489  [870464/986091]
loss: 0.298075  [876864/986091]
loss: 0.510954  [883264/986091]
loss: 0.430247  [889664/986091]
loss: 0.311970  [896064/986091]
loss: 0.482271  [902464/986091]
loss: 0.359532  [908864/986091]
loss: 0.423172  [915264/986091]
loss: 0.360170  [921664/986091]
loss: 0.536728  [928064/986091]
loss: 0.558483  [934464/986091]
loss: 0.434537  [940864/986091]
loss: 0.372456  [947264/986091]
loss: 0.540036  [953664/986091]
loss: 0.153239  [960064/986091]
loss: 0.412487  [966464/986091]
loss: 0.330556  [972864/986091]
loss: 0.544678  [979264/986091]
loss: 0.236903  [985664/986091]
Epoch 4/5, Training Loss (epoch avg): 0.4474, Test Loss: 0.5049, Test Accuracy: 82.32%
loss: 0.495570  [   64/986091]
loss: 0.496355  [ 6464/986091]
loss: 0.332832  [12864/986091]
loss: 0.551772  [19264/986091]
loss: 0.471924  [25664/986091]
loss: 0.401624  [32064/986091]
loss: 0.384125  [38464/986091]
loss: 0.530862  [44864/986091]
loss: 0.475770  [51264/986091]
loss: 0.543081  [57664/986091]
loss: 0.320509  [64064/986091]
loss: 0.509396  [70464/986091]
loss: 0.555611  [76864/986091]
loss: 0.475746  [83264/986091]
loss: 0.463859  [89664/986091]
loss: 0.406635  [96064/986091]
loss: 0.441070  [102464/986091]
loss: 0.327009  [108864/986091]
loss: 0.556732  [115264/986091]
loss: 0.372051  [121664/986091]
loss: 0.351695  [128064/986091]
loss: 0.601216  [134464/986091]
loss: 0.544908  [140864/986091]
loss: 0.418859  [147264/986091]
loss: 0.249030  [153664/986091]
loss: 0.290138  [160064/986091]
loss: 0.367456  [166464/986091]
loss: 0.471709  [172864/986091]
loss: 0.640368  [179264/986091]
loss: 0.548306  [185664/986091]
loss: 0.459648  [192064/986091]
loss: 0.493260  [198464/986091]
loss: 0.352409  [204864/986091]
loss: 0.376234  [211264/986091]
loss: 0.541600  [217664/986091]
loss: 0.448946  [224064/986091]
loss: 0.681547  [230464/986091]
loss: 0.471039  [236864/986091]
loss: 0.404085  [243264/986091]
loss: 0.346522  [249664/986091]
loss: 0.289592  [256064/986091]
loss: 0.198878  [262464/986091]
loss: 0.501160  [268864/986091]
loss: 0.341793  [275264/986091]
loss: 0.281923  [281664/986091]
loss: 0.303987  [288064/986091]
loss: 0.388033  [294464/986091]
loss: 0.370310  [300864/986091]
loss: 0.470722  [307264/986091]
loss: 0.582543  [313664/986091]
loss: 0.379508  [320064/986091]
loss: 0.427104  [326464/986091]
loss: 0.406597  [332864/986091]
loss: 0.322306  [339264/986091]
loss: 0.373264  [345664/986091]
loss: 0.231938  [352064/986091]
loss: 0.225902  [358464/986091]
loss: 0.551165  [364864/986091]
loss: 0.326656  [371264/986091]
loss: 0.232996  [377664/986091]
loss: 0.424538  [384064/986091]
loss: 0.485761  [390464/986091]
loss: 0.578328  [396864/986091]
loss: 0.436070  [403264/986091]
loss: 0.305027  [409664/986091]
loss: 0.319273  [416064/986091]
loss: 0.507199  [422464/986091]
loss: 0.375648  [428864/986091]
loss: 0.245389  [435264/986091]
loss: 0.537781  [441664/986091]
loss: 0.361168  [448064/986091]
loss: 0.419239  [454464/986091]
loss: 0.351565  [460864/986091]
loss: 0.395735  [467264/986091]
loss: 0.447195  [473664/986091]
loss: 0.274573  [480064/986091]
loss: 0.345901  [486464/986091]
loss: 0.412521  [492864/986091]
loss: 0.680584  [499264/986091]
loss: 0.427063  [505664/986091]
loss: 0.622457  [512064/986091]
loss: 0.471390  [518464/986091]
loss: 0.483355  [524864/986091]
loss: 0.491197  [531264/986091]
loss: 0.316374  [537664/986091]
loss: 0.370846  [544064/986091]
loss: 0.380355  [550464/986091]
loss: 0.630264  [556864/986091]
loss: 0.400380  [563264/986091]
loss: 0.368094  [569664/986091]
loss: 0.477092  [576064/986091]
loss: 0.335434  [582464/986091]
loss: 0.411867  [588864/986091]
loss: 0.359032  [595264/986091]
loss: 0.397499  [601664/986091]
loss: 0.594965  [608064/986091]
loss: 0.460265  [614464/986091]
loss: 0.433155  [620864/986091]
loss: 0.318449  [627264/986091]
loss: 0.574387  [633664/986091]
loss: 0.320218  [640064/986091]
loss: 0.246059  [646464/986091]
loss: 0.628837  [652864/986091]
loss: 0.504516  [659264/986091]
loss: 0.507028  [665664/986091]
loss: 0.283790  [672064/986091]
loss: 0.490983  [678464/986091]
loss: 0.371462  [684864/986091]
loss: 0.635042  [691264/986091]
loss: 0.460111  [697664/986091]
loss: 0.316134  [704064/986091]
loss: 0.671704  [710464/986091]
loss: 0.463994  [716864/986091]
loss: 0.312431  [723264/986091]
loss: 0.450224  [729664/986091]
loss: 0.381941  [736064/986091]
loss: 0.442528  [742464/986091]
loss: 0.415251  [748864/986091]
loss: 0.432793  [755264/986091]
loss: 0.466139  [761664/986091]
loss: 0.356830  [768064/986091]
loss: 0.350548  [774464/986091]
loss: 0.528116  [780864/986091]
loss: 0.202229  [787264/986091]
loss: 0.429612  [793664/986091]
loss: 0.344170  [800064/986091]
loss: 0.256586  [806464/986091]
loss: 0.414233  [812864/986091]
loss: 0.278882  [819264/986091]
loss: 0.306950  [825664/986091]
loss: 0.438497  [832064/986091]
loss: 0.477690  [838464/986091]
loss: 0.343975  [844864/986091]
loss: 0.418182  [851264/986091]
loss: 0.246490  [857664/986091]
loss: 0.682647  [864064/986091]
loss: 0.365260  [870464/986091]
loss: 0.274853  [876864/986091]
loss: 0.539595  [883264/986091]
loss: 0.327256  [889664/986091]
loss: 0.386958  [896064/986091]
loss: 0.489716  [902464/986091]
loss: 0.259196  [908864/986091]
loss: 0.453393  [915264/986091]
loss: 0.284687  [921664/986091]
loss: 0.414052  [928064/986091]
loss: 0.402667  [934464/986091]
loss: 0.389780  [940864/986091]
loss: 0.346164  [947264/986091]
loss: 0.487392  [953664/986091]
loss: 0.138806  [960064/986091]
loss: 0.413618  [966464/986091]
loss: 0.389019  [972864/986091]
loss: 0.441426  [979264/986091]
loss: 0.277888  [985664/986091]
Epoch 5/5, Training Loss (epoch avg): 0.4213, Test Loss: 0.5189, Test Accuracy: 82.09%
